{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code to calculate the correlations (within-subject) between brain and behavior (table 1 in paper) for all 5 neural codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "import seaborn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load neural strength values for perception code\n",
    "\n",
    "file_path_perception = \"/Users/silvycollin/Documents/GitHub/schema/final_code/roi_average_folder_Ross/perception_per_ritual_within_wedding_notdistilled_madeAfterPvalues.json\"\n",
    "\n",
    "# function to load json file\n",
    "with open(file_path_perception, \"r\") as json_file:\n",
    "    dictionary_with_info_perception = json.load(json_file) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load neural strength values for schema code\n",
    "\n",
    "file_path_schema = \"/Users/silvycollin/Documents/GitHub/schema/final_code/roi_average_folder_Ross/schema_per_ritual_within_wedding_notdistilled_madeAfterPvalues.json\"\n",
    "\n",
    "# function to load json file\n",
    "with open(file_path_schema, \"r\") as json_file:\n",
    "    dictionary_with_info_schema = json.load(json_file) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load neural strength values for path code\n",
    "\n",
    "file_path_revisedpath = \"/Users/silvycollin/Documents/GitHub/schema/final_code/roi_average_folder_Ross/REVISED_path_per_ritual_within_wedding_notdistilled_madeAfterPvalues.json\"\n",
    "\n",
    "# function to load json file\n",
    "with open(file_path_revisedpath, \"r\") as json_file:\n",
    "    dictionary_with_info_revisedpath = json.load(json_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load neural strength values for rotated minus perception code\n",
    "\n",
    "file_path_rotatedminusperception = \"/Users/silvycollin/Documents/GitHub/schema/final_code/roi_average_folder_Ross/rotatedminusperception_per_ritual_within_wedding_notdistilled_madeAfterPvalues.json\"\n",
    "\n",
    "# function to load json file\n",
    "with open(file_path_rotatedminusperception, \"r\") as json_file:\n",
    "    dictionary_with_info_rotatedminusperception = json.load(json_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load neural strength values for perception minus rotated code\n",
    "\n",
    "file_path_perceptionminusrotated = \"/Users/silvycollin/Documents/GitHub/schema/final_code/roi_average_folder_Ross/perceptionminusrotated_per_ritual_within_wedding_notdistilled_madeAfterPvalues.json\"\n",
    "\n",
    "# function to load json file\n",
    "with open(file_path_perceptionminusrotated, \"r\") as json_file:\n",
    "    dictionary_with_info_perceptionminusrotated = json.load(json_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load neural strength values for perception and rotated code, two versions (based on rotated or based on perception)\n",
    "\n",
    "## CHOOSE FROM BELOW\n",
    "# neural strength based on rotated code\n",
    "#file_path_rotatedandperception = \"/Users/silvycollin/Documents/GitHub/schema/final_code/roi_average_folder_Ross/rotatedandperception_per_ritual_within_wedding_notdistilled_madeAfterPvalues.json\"\n",
    "\n",
    "# neural strength based on perception code\n",
    "file_path_rotatedandperception = \"/Users/silvycollin/Documents/GitHub/schema/final_code/roi_average_folder_Ross/rotatedandpercerception_perceptionvalues_per_ritual_within_wedding_notdistilled_madeAfterPvalues.json\"\n",
    "\n",
    "\n",
    "# function to load json file\n",
    "with open(file_path_rotatedandperception, \"r\") as json_file:\n",
    "    dictionary_with_info_rotatedandperception = json.load(json_file)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "\n",
    "AllSubjects = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,17,18,19,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load schema behav\n",
    "schematest = pd.read_csv('/Volumes/norman/scollin/schema/data/behav/results/Schematest.csv')\n",
    "schematest['diffScore'] = schematest['Correct'] - schematest['Opposite']\n",
    "\n",
    "## load recall behav measures\n",
    "EpisodicDetails_Correct = pd.read_csv('/Volumes/norman/scollin/schema/data/behav/recallTranscriptions/EpisodicDetails_Correct.csv')\n",
    "EpisodicDetails_Incorrect = pd.read_csv('/Volumes/norman/scollin/schema/data/behav/recallTranscriptions/EpisodicDetails_Incorrect.csv')\n",
    "Rituals_Correct =  pd.read_csv('/Volumes/norman/scollin/schema/data/behav/recallTranscriptions/Rituals_Correct.csv')\n",
    "Rituals_Incorrect =  pd.read_csv('/Volumes/norman/scollin/schema/data/behav/recallTranscriptions/Rituals_Incorrect.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCHEMA CODE TO BEHAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema code\n",
    "\n",
    "result_schema = pd.DataFrame(columns=[])\n",
    "result_schema_r = pd.DataFrame(columns=[])\n",
    "result_schema_r_rituals = pd.DataFrame(columns=[])\n",
    "\n",
    "for CurrSub in AllSubjects: \n",
    "\n",
    "    sub = \"sub-1%02d\" % (CurrSub)\n",
    "        #print(sub)\n",
    "    sub2 = 's%d' % (CurrSub)\n",
    "\n",
    "    Correct_minus_Incorrect_Details = EpisodicDetails_Correct.loc[:, [sub2]]-EpisodicDetails_Incorrect.loc[:, [sub2]] \n",
    "    Correct_minus_Incorrect_Rituals = Rituals_Correct.loc[:, [sub2]]-Rituals_Incorrect.loc[:, [sub2]] \n",
    "\n",
    "    result_schema_tmp = pd.DataFrame(columns=[])\n",
    "    result_schema_tmp_subj = pd.DataFrame(columns=[])\n",
    "\n",
    "    for currLoop in range(12): # loop over 12 weddings\n",
    "\n",
    "        result_schema_averageCurrLoop = pd.DataFrame(columns=[])\n",
    "\n",
    "            #append event2\n",
    "        result_schema_tmp = result_schema_tmp.append(pd.Series(dictionary_with_info_schema[sub][str(currLoop)]['2'],name=currLoop))\n",
    "        result_schema_averageCurrLoop = result_schema_averageCurrLoop.append(pd.Series(dictionary_with_info_schema[sub][str(currLoop)]['2'],name=currLoop))\n",
    "\n",
    "            #append event3\n",
    "        result_schema_tmp = result_schema_tmp.append(pd.Series(dictionary_with_info_schema[sub][str(currLoop)]['3'],name=currLoop))\n",
    "        result_schema_averageCurrLoop = result_schema_averageCurrLoop.append(pd.Series(dictionary_with_info_schema[sub][str(currLoop)]['3'],name=currLoop))\n",
    "\n",
    "            #append event4\n",
    "        result_schema_tmp = result_schema_tmp.append(pd.Series(dictionary_with_info_schema[sub][str(currLoop)]['4'],name=currLoop))\n",
    "        result_schema_averageCurrLoop = result_schema_averageCurrLoop.append(pd.Series(dictionary_with_info_schema[sub][str(currLoop)]['4'],name=currLoop))\n",
    "\n",
    "        result_schema_tmp_subj = result_schema_tmp_subj.append(pd.Series(result_schema_averageCurrLoop.mean(),name=currLoop))\n",
    "        \n",
    "        # append average (across event2/3/4) of subj to result_schema dataframe\n",
    "        #print(result_schema_tmp)\n",
    "\n",
    "    result_schema = result_schema.append(pd.Series(result_schema_tmp.mean(),name=CurrSub))\n",
    "\n",
    "    #within subj correlation\n",
    "    result_schema_r = result_schema_r.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Details,result_schema_tmp_subj)[0],name=CurrSub))\n",
    "    result_schema_r_rituals = result_schema_r_rituals.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Rituals,result_schema_tmp_subj)[0],name=CurrSub))\n",
    "\n",
    "    print(Correct_minus_Incorrect_Details)\n",
    "    \n",
    "#fisher z transform before t test\n",
    "result_schema_r_fisherz = np.arctanh(result_schema_r)\n",
    "result_schema_r_rituals_fisherz = np.arctanh(result_schema_r_rituals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,10))\n",
    "\n",
    "plt.axhline(y=0, color='k')\n",
    "plt.axvline(x=0, color='k')\n",
    "\n",
    "for CurrSub in range(40):\n",
    "    plt.plot([random.random()+0.5],np.array(result_schema_r_fisherz)[CurrSub], 'ko')\n",
    "\n",
    "plt.xticks([1], [\" \"], fontsize=18)\n",
    "# plt.yticks(np.arange(-0.15, 0.15, step=0.05), fontsize=18)\n",
    "# plt.ylim([-.15,.15])\n",
    "\n",
    "plt.ylabel('correlation (schema strength to memory for details)', fontsize=18)\n",
    "plt.xlim([0,6])\n",
    "seaborn.despine(left=True, bottom=True, right=True)\n",
    "\n",
    "plt.bar([1],result_schema_r_fisherz.mean(), color='black',alpha=0.5)\n",
    "plt.errorbar([1],result_schema_r_fisherz.mean(),result_schema_r_fisherz.sem(), color='black',alpha=0.5)\n",
    "\n",
    "fname_paperFigure='/Users/silvycollin/Documents/GitHub/schema/final_code/roi_average_folder_Ross/final_figures_GoodResolution/V2_detailsVSschema_fig.eps'\n",
    "plt.savefig(fname_paperFigure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,10))\n",
    "\n",
    "plt.axhline(y=0, color='k')\n",
    "plt.axvline(x=0, color='k')\n",
    "\n",
    "for CurrSub in range(40):\n",
    "    plt.plot([random.random()+0.5],np.array(result_schema_r_rituals_fisherz)[CurrSub], 'ko')\n",
    "\n",
    "plt.xticks([1], [\" \"], fontsize=18)\n",
    "# plt.yticks(np.arange(-0.15, 0.15, step=0.05), fontsize=18)\n",
    "# plt.ylim([-.15,.15])\n",
    "\n",
    "plt.ylabel('correlation (schema strength to memory for rituals)', fontsize=18)\n",
    "plt.xlim([0,6])\n",
    "seaborn.despine(left=True, bottom=True, right=True)\n",
    "\n",
    "plt.bar([1],result_schema_r_rituals_fisherz.mean(), color='black',alpha=0.5)\n",
    "plt.errorbar([1],result_schema_r_rituals_fisherz.mean(),result_schema_r_rituals_fisherz.sem(), color='black',alpha=0.5)\n",
    "\n",
    "fname_paperFigure='/Users/silvycollin/Documents/GitHub/schema/final_code/roi_average_folder_Ross/final_figures_GoodResolution/V2_ritualsVSschema_fig.eps'\n",
    "plt.savefig(fname_paperFigure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## null distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ONLY RAN ONCE, THEN SAVED NULL DISTRIBUTIONS (CAN BE LOADED WITH SUBSEQUENT CODE BLOCK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema code\n",
    "\n",
    "result_schema_ttest_nullDistribution = pd.DataFrame(columns=[])\n",
    "result_schema_ttest_rituals_nullDistribution = pd.DataFrame(columns=[])\n",
    "result_schema_ttest_confusions_nullDistribution = pd.DataFrame(columns=[])\n",
    "\n",
    "for currIter in range(1000): \n",
    "\n",
    "    shuffle_tmp = pd.DataFrame(columns=[])\n",
    "    shuffle_tmp2 = pd.DataFrame(columns=[])\n",
    "    shuffle_tmp3 = pd.DataFrame(columns=[])\n",
    "    \n",
    "    for CurrSub in AllSubjects: \n",
    "\n",
    "        sub = \"sub-1%02d\" % (CurrSub)\n",
    "        #print(sub)\n",
    "        sub2 = 's%d' % (CurrSub)\n",
    "\n",
    "        Correct_minus_Incorrect_Details = EpisodicDetails_Correct.loc[:, [sub2]]-EpisodicDetails_Incorrect.loc[:, [sub2]] \n",
    "        Correct_minus_Incorrect_Rituals = Rituals_Correct.loc[:, [sub2]]-Rituals_Incorrect.loc[:, [sub2]] \n",
    "        Correct_minus_Incorrect_Confusions = EpisodicDetails_withinSchemaConfusions.loc[:, [sub2]]-EpisodicDetails_acrossSchemaConfusions.loc[:, [sub2]] \n",
    "    \n",
    "        result_schema_tmp = pd.DataFrame(columns=[])\n",
    "        result_schema_tmp_subj = pd.DataFrame(columns=[])\n",
    "\n",
    "        for currLoop in range(12): # loop over 12 weddings\n",
    "\n",
    "            result_schema_averageCurrLoop = pd.DataFrame(columns=[])\n",
    "\n",
    "            #append event2\n",
    "            result_schema_tmp = result_schema_tmp.append(pd.Series(dictionary_with_info_schema[sub][str(currLoop)]['2'],name=currLoop))\n",
    "            result_schema_averageCurrLoop = result_schema_averageCurrLoop.append(pd.Series(dictionary_with_info_schema[sub][str(currLoop)]['2'],name=currLoop))\n",
    "\n",
    "            #append event3\n",
    "            result_schema_tmp = result_schema_tmp.append(pd.Series(dictionary_with_info_schema[sub][str(currLoop)]['3'],name=currLoop))\n",
    "            result_schema_averageCurrLoop = result_schema_averageCurrLoop.append(pd.Series(dictionary_with_info_schema[sub][str(currLoop)]['3'],name=currLoop))\n",
    "\n",
    "            #append event4\n",
    "            result_schema_tmp = result_schema_tmp.append(pd.Series(dictionary_with_info_schema[sub][str(currLoop)]['4'],name=currLoop))\n",
    "            result_schema_averageCurrLoop = result_schema_averageCurrLoop.append(pd.Series(dictionary_with_info_schema[sub][str(currLoop)]['4'],name=currLoop))\n",
    "\n",
    "            result_schema_tmp_subj = result_schema_tmp_subj.append(pd.Series(result_schema_averageCurrLoop.mean(),name=currLoop))\n",
    "\n",
    "        ## create null distribution by shuffling behavioral scores of 12 weddings within subj and then run correlation, 1000 times\n",
    "        Correct_minus_Incorrect_Details_shuffle = shuffle(Correct_minus_Incorrect_Details)\n",
    "        Correct_minus_Incorrect_Details_shuffle = Correct_minus_Incorrect_Details_shuffle.to_numpy()\n",
    "        shuffle_tmp = shuffle_tmp.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Details_shuffle,result_schema_tmp_subj)[0],name=CurrSub))\n",
    "\n",
    "        Correct_minus_Incorrect_Rituals_shuffle = shuffle(Correct_minus_Incorrect_Rituals)\n",
    "        Correct_minus_Incorrect_Rituals_shuffle = Correct_minus_Incorrect_Rituals_shuffle.to_numpy()\n",
    "        shuffle_tmp2 = shuffle_tmp2.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Rituals_shuffle,result_schema_tmp_subj)[0],name=CurrSub))\n",
    "\n",
    "        Correct_minus_Incorrect_Confusions_shuffle = shuffle(Correct_minus_Incorrect_Confusions)\n",
    "        Correct_minus_Incorrect_Confusions_shuffle = Correct_minus_Incorrect_Confusions_shuffle.to_numpy()\n",
    "        shuffle_tmp3 = shuffle_tmp2.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Confusions_shuffle,result_schema_tmp_subj)[0],name=CurrSub))\n",
    "\n",
    "    #fisher z transform before t test\n",
    "    shuffle_tmp_fisherz = np.arctanh(shuffle_tmp)\n",
    "    shuffle_tmp2_fisherz = np.arctanh(shuffle_tmp2)\n",
    "    shuffle_tmp3_fisherz = np.arctanh(shuffle_tmp3)\n",
    "\n",
    "    result_schema_ttest_nullDistribution = result_schema_ttest_nullDistribution.append(pd.Series(stats.ttest_1samp(shuffle_tmp_fisherz,popmean=0)[0],name=currIter))\n",
    "    result_schema_ttest_rituals_nullDistribution = result_schema_ttest_rituals_nullDistribution.append(pd.Series(stats.ttest_1samp(shuffle_tmp2_fisherz,popmean=0)[0],name=currIter))\n",
    "    result_schema_ttest_confusions_nullDistribution = result_schema_ttest_confusions_nullDistribution.append(pd.Series(stats.ttest_1samp(shuffle_tmp3_fisherz,popmean=0)[0],name=currIter))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_schema_ttest_nullDistribution.to_csv('result_schema_ttest_nullDistribution_NEW.csv')\n",
    "result_schema_ttest_rituals_nullDistribution.to_csv('result_schema_ttest_rituals_nullDistribution_NEW.csv')\n",
    "result_schema_ttest_confusions_nullDistribution.to_csv('result_schema_ttest_confusions_nullDistribution_NEW.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD NULL DISTRIBUTIONS (SINCE IT WAS ALREADY RAN AND SAVED)\n",
    "\n",
    "result_schema_ttest_nullDistribution = pd.read_csv('/Users/silvycollin/Documents/GitHub/schema/final_code/roi_average_folder_Ross/result_schema_ttest_nullDistribution_NEW.csv')\n",
    "result_schema_ttest_rituals_nullDistribution = pd.read_csv('/Users/silvycollin/Documents/GitHub/schema/final_code/roi_average_folder_Ross/result_schema_ttest_rituals_nullDistribution_NEW.csv')\n",
    "result_schema_ttest_confusions_nullDistribution = pd.read_csv('/Users/silvycollin/Documents/GitHub/schema/final_code/roi_average_folder_Ross/result_schema_ttest_confusions_nullDistribution_NEW.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the mean and sem of the R values\n",
    "\n",
    "print('mean r (details)', result_schema_r_fisherz.mean())\n",
    "print('sem r (details)', result_schema_r_fisherz.sem())\n",
    "\n",
    "print('mean r (rituals)', result_schema_r_rituals_fisherz.mean())\n",
    "print('sem r (rituals)', result_schema_r_rituals_fisherz.sem())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot null distribution details\n",
    "x = np.arange(0,1000,1)\n",
    "y = result_schema_ttest_nullDistribution['0'].to_numpy()\n",
    "y = np.reshape(y, (-1,))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(y,bins=100)\n",
    "plt.axvline(stats.ttest_1samp(result_schema_r_fisherz,popmean=0)[0],color='r')\n",
    "\n",
    "print('instances above red line:', np.count_nonzero(y > stats.ttest_1samp(result_schema_r_fisherz,popmean=0)[0]))\n",
    "print('p val from distribution:', np.count_nonzero(y > stats.ttest_1samp(result_schema_r_fisherz,popmean=0)[0]) / len(y))\n",
    "\n",
    "s = 'p = ' + str(np.count_nonzero(y > stats.ttest_1samp(result_schema_r_fisherz,popmean=0)[0]) / len(y))\n",
    "\n",
    "plt.text(-3,35,s)\n",
    "\n",
    "plt.savefig('/Users/silvycollin/Documents/GitHub/schema/final_code/roi_average_folder_Ross/final_figures_GoodResolution/details_vs_schemaStrength_tscores_to_null_NEW.eps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot null distribution rituals\n",
    "x = np.arange(0,1000,1)\n",
    "y = result_schema_ttest_rituals_nullDistribution['0'].to_numpy()\n",
    "y = np.reshape(y, (-1,))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(y,bins=100)\n",
    "plt.axvline(stats.ttest_1samp(result_schema_r_rituals_fisherz,popmean=0)[0],color='r')\n",
    "\n",
    "print('instances above red line:', np.count_nonzero(y > stats.ttest_1samp(result_schema_r_rituals_fisherz,popmean=0)[0]))\n",
    "print('p val from distribution:', np.count_nonzero(y > stats.ttest_1samp(result_schema_r_rituals_fisherz,popmean=0)[0]) / len(y))\n",
    "\n",
    "s = 'p = ' + str(np.count_nonzero(y > stats.ttest_1samp(result_schema_r_rituals_fisherz,popmean=0)[0]) / len(y))\n",
    "\n",
    "plt.text(-3,35,s)\n",
    "\n",
    "\n",
    "plt.savefig('/Users/silvycollin/Documents/GitHub/schema/final_code/roi_average_folder_Ross/final_figures_GoodResolution/rituals_vs_schemaStrength_tscores_to_null_NEW.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REVISED PATH CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "result_path = pd.DataFrame(columns=[])\n",
    "result_path_r = pd.DataFrame(columns=[])\n",
    "result_path_r_rituals = pd.DataFrame(columns=[])\n",
    "result_path_r_confusions = pd.DataFrame(columns=[])\n",
    "\n",
    "for CurrSub in AllSubjects: \n",
    "\n",
    "    sub = \"sub-1%02d\" % (CurrSub)\n",
    "    #print(sub)\n",
    "    sub2 = 's%d' % (CurrSub)\n",
    "    \n",
    "    Correct_minus_Incorrect_Details = EpisodicDetails_Correct.loc[:, [sub2]]-EpisodicDetails_Incorrect.loc[:, [sub2]]\n",
    "    Correct_minus_Incorrect_Rituals = Rituals_Correct.loc[:, [sub2]]-Rituals_Incorrect.loc[:, [sub2]] \n",
    "    Correct_minus_Incorrect_Confusions = EpisodicDetails_withinSchemaConfusions.loc[:, [sub2]]-EpisodicDetails_acrossSchemaConfusions.loc[:, [sub2]] \n",
    "    \n",
    "    result_path_tmp = pd.DataFrame(columns=[])\n",
    "    result_path_tmp_subj = pd.DataFrame(columns=[])\n",
    "    \n",
    "    for currLoop in range(12): # loop over 12 weddings\n",
    "        \n",
    "        result_path_averageCurrLoop = pd.DataFrame(columns=[])\n",
    "        \n",
    "        #append event2\n",
    "        result_path_tmp = result_path_tmp.append(pd.Series(dictionary_with_info_revisedpath[sub][str(currLoop)]['2'],name=currLoop))\n",
    "        result_path_averageCurrLoop = result_path_averageCurrLoop.append(pd.Series(dictionary_with_info_revisedpath[sub][str(currLoop)]['2'],name=currLoop))\n",
    "\n",
    "        #append event3\n",
    "        result_path_tmp = result_path_tmp.append(pd.Series(dictionary_with_info_revisedpath[sub][str(currLoop)]['3'],name=currLoop))\n",
    "        result_path_averageCurrLoop = result_path_averageCurrLoop.append(pd.Series(dictionary_with_info_revisedpath[sub][str(currLoop)]['3'],name=currLoop))\n",
    "\n",
    "        #append event4\n",
    "        result_path_tmp = result_path_tmp.append(pd.Series(dictionary_with_info_revisedpath[sub][str(currLoop)]['4'],name=currLoop))\n",
    "        result_path_averageCurrLoop = result_path_averageCurrLoop.append(pd.Series(dictionary_with_info_revisedpath[sub][str(currLoop)]['4'],name=currLoop))\n",
    "\n",
    "        result_path_tmp_subj = result_path_tmp_subj.append(pd.Series(result_path_averageCurrLoop.mean(),name=currLoop))\n",
    "        \n",
    "    # append average (across event2/3/4) of subj to result_perception dataframe\n",
    "    \n",
    "    result_path = result_path.append(pd.Series(result_path_tmp.mean(),name=CurrSub))\n",
    "\n",
    "    #within subj correlation\n",
    "    result_path_r = result_path_r.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Details,result_path_tmp_subj)[0],name=CurrSub))\n",
    "    result_path_r_rituals = result_path_r_rituals.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Rituals,result_path_tmp_subj)[0],name=CurrSub))\n",
    "    result_path_r_confusions = result_path_r_confusions.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Confusions,result_path_tmp_subj)[0],name=CurrSub))\n",
    "\n",
    "#fisher z transform before t test\n",
    "result_path_r_fisherz = np.arctanh(result_path_r)\n",
    "result_path_r_rituals_fisherz = np.arctanh(result_path_r_rituals)\n",
    "result_path_r_confusions_fisherz = np.arctanh(result_path_r_confusions)\n",
    "\n",
    "    \n",
    "# print(stats.ttest_1samp(result_path_r_fisherz,popmean=0))\n",
    "# print(stats.ttest_1samp(result_path_r_rituals_fisherz,popmean=0))\n",
    "# print(stats.ttest_1samp(result_path_r_confusions_fisherz,popmean=0))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path_ttest_nullDistribution = pd.DataFrame(columns=[])\n",
    "result_path_ttest_rituals_nullDistribution = pd.DataFrame(columns=[])\n",
    "result_path_ttest_confusions_nullDistribution = pd.DataFrame(columns=[])\n",
    "\n",
    "for currIter in range(1000): \n",
    "\n",
    "    print(currIter)\n",
    "    \n",
    "    shuffle_tmp = pd.DataFrame(columns=[])\n",
    "    shuffle_tmp2 = pd.DataFrame(columns=[])\n",
    "    shuffle_tmp3 = pd.DataFrame(columns=[])\n",
    "\n",
    "    for CurrSub in AllSubjects: \n",
    "\n",
    "        sub = \"sub-1%02d\" % (CurrSub)\n",
    "        #print(sub)\n",
    "        sub2 = 's%d' % (CurrSub)\n",
    "\n",
    "        Correct_minus_Incorrect_Details = EpisodicDetails_Correct.loc[:, [sub2]]-EpisodicDetails_Incorrect.loc[:, [sub2]] \n",
    "        Correct_minus_Incorrect_Rituals = Rituals_Correct.loc[:, [sub2]]-Rituals_Incorrect.loc[:, [sub2]]\n",
    "        Correct_minus_Incorrect_Confusions = EpisodicDetails_withinSchemaConfusions.loc[:, [sub2]]-EpisodicDetails_acrossSchemaConfusions.loc[:, [sub2]] \n",
    "    \n",
    "   \n",
    "        result_path_tmp = pd.DataFrame(columns=[])\n",
    "        result_path_tmp_subj = pd.DataFrame(columns=[])\n",
    "\n",
    "        for currLoop in range(12): # loop over 12 weddings\n",
    "\n",
    "            result_path_averageCurrLoop = pd.DataFrame(columns=[])\n",
    "\n",
    "            #append event2\n",
    "            result_path_tmp = result_path_tmp.append(pd.Series(dictionary_with_info_revisedpath[sub][str(currLoop)]['2'],name=currLoop))\n",
    "            result_path_averageCurrLoop = result_path_averageCurrLoop.append(pd.Series(dictionary_with_info_revisedpath[sub][str(currLoop)]['2'],name=currLoop))\n",
    "            \n",
    "            #append event3\n",
    "            result_path_tmp = result_path_tmp.append(pd.Series(dictionary_with_info_revisedpath[sub][str(currLoop)]['3'],name=currLoop))\n",
    "            result_path_averageCurrLoop = result_path_averageCurrLoop.append(pd.Series(dictionary_with_info_revisedpath[sub][str(currLoop)]['3'],name=currLoop))\n",
    "\n",
    "            #append event4\n",
    "            result_path_tmp = result_path_tmp.append(pd.Series(dictionary_with_info_revisedpath[sub][str(currLoop)]['4'],name=currLoop))\n",
    "            result_path_averageCurrLoop = result_path_averageCurrLoop.append(pd.Series(dictionary_with_info_revisedpath[sub][str(currLoop)]['4'],name=currLoop))\n",
    "\n",
    "            result_path_tmp_subj = result_path_tmp_subj.append(pd.Series(result_path_averageCurrLoop.mean(),name=currLoop))\n",
    "\n",
    "        ## create null distribution by shuffling behavioral scores of 12 weddings within subj and then run correlation, 1000 times\n",
    "        Correct_minus_Incorrect_Details_shuffle = shuffle(Correct_minus_Incorrect_Details)\n",
    "        Correct_minus_Incorrect_Details_shuffle = Correct_minus_Incorrect_Details_shuffle.to_numpy()\n",
    "        shuffle_tmp = shuffle_tmp.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Details_shuffle,result_path_tmp_subj)[0],name=CurrSub))\n",
    "\n",
    "        Correct_minus_Incorrect_Rituals_shuffle = shuffle(Correct_minus_Incorrect_Rituals)\n",
    "        Correct_minus_Incorrect_Rituals_shuffle = Correct_minus_Incorrect_Rituals_shuffle.to_numpy()\n",
    "        shuffle_tmp2 = shuffle_tmp2.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Rituals_shuffle,result_path_tmp_subj)[0],name=CurrSub))\n",
    "        \n",
    "        Correct_minus_Incorrect_Confusions_shuffle = shuffle(Correct_minus_Incorrect_Confusions)\n",
    "        Correct_minus_Incorrect_Confusions_shuffle = Correct_minus_Incorrect_Confusions_shuffle.to_numpy()\n",
    "        shuffle_tmp3 = shuffle_tmp2.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Confusions_shuffle,result_path_tmp_subj)[0],name=CurrSub))\n",
    "\n",
    "\n",
    "    #fisher z transform before t test\n",
    "    shuffle_tmp_fisherz = np.arctanh(shuffle_tmp)\n",
    "    shuffle_tmp2_fisherz = np.arctanh(shuffle_tmp2)\n",
    "    shuffle_tmp3_fisherz = np.arctanh(shuffle_tmp3)\n",
    "\n",
    "    result_path_ttest_nullDistribution = result_path_ttest_nullDistribution.append(pd.Series(stats.ttest_1samp(shuffle_tmp_fisherz,popmean=0)[0],name=currIter))\n",
    "    result_path_ttest_rituals_nullDistribution = result_path_ttest_rituals_nullDistribution.append(pd.Series(stats.ttest_1samp(shuffle_tmp2_fisherz,popmean=0)[0],name=currIter))\n",
    "\n",
    "    result_path_ttest_confusions_nullDistribution = result_path_ttest_confusions_nullDistribution.append(pd.Series(stats.ttest_1samp(shuffle_tmp3_fisherz,popmean=0)[0],name=currIter))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path_ttest_nullDistribution.to_csv('result_revisedpath_ttest_nullDistribution_NEW.csv')\n",
    "result_path_ttest_rituals_nullDistribution.to_csv('result_revisedpath_ttest_rituals_nullDistribution_NEW.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the mean and sem of the R values\n",
    "\n",
    "print('mean r (details)', result_path_r_fisherz.mean())\n",
    "print('sem r (details)', result_path_r_fisherz.sem())\n",
    "\n",
    "print('mean r (rituals)', result_path_r_rituals_fisherz.mean())\n",
    "print('sem r (rituals)', result_path_r_rituals_fisherz.sem())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot null distribution details\n",
    "x = np.arange(0,1000,1)\n",
    "y = result_path_ttest_nullDistribution[0].to_numpy()\n",
    "y = np.reshape(y, (-1,))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(y,bins=100)\n",
    "plt.axvline(stats.ttest_1samp(result_path_r_fisherz,popmean=0)[0],color='r')\n",
    "\n",
    "print('instances above red line:', np.count_nonzero(y > stats.ttest_1samp(result_path_r_fisherz,popmean=0)[0]))\n",
    "print('p val from distribution:', np.count_nonzero(y > stats.ttest_1samp(result_path_r_fisherz,popmean=0)[0]) / len(y))\n",
    "\n",
    "s = 'p = ' + str(np.count_nonzero(y > stats.ttest_1samp(result_path_r_fisherz,popmean=0)[0]) / len(y))\n",
    "\n",
    "plt.text(-3,35,s)\n",
    "\n",
    "plt.savefig('details_vs_revisedpathStrength_tscores_to_nullNEW.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot null distribution rituals\n",
    "x = np.arange(0,1000,1)\n",
    "y = result_path_ttest_rituals_nullDistribution[0].to_numpy()\n",
    "y = np.reshape(y, (-1,))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(y,bins=100)\n",
    "plt.axvline(stats.ttest_1samp(result_path_r_rituals_fisherz,popmean=0)[0],color='r')\n",
    "\n",
    "print('instances above red line:', np.count_nonzero(y > stats.ttest_1samp(result_path_r_rituals_fisherz,popmean=0)[0]))\n",
    "print('p val from distribution:', np.count_nonzero(y > stats.ttest_1samp(result_path_r_rituals_fisherz,popmean=0)[0]) / len(y))\n",
    "\n",
    "s = 'p = ' + str(np.count_nonzero(y > stats.ttest_1samp(result_path_r_rituals_fisherz,popmean=0)[0]) / len(y))\n",
    "\n",
    "plt.text(-3,35,s)\n",
    "\n",
    "\n",
    "plt.savefig('rituals_vs_revisedpathStrength_tscores_to_nullNEW.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PERCEPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_perception = pd.DataFrame(columns=[])\n",
    "result_perception_r = pd.DataFrame(columns=[])\n",
    "result_perception_r_rituals = pd.DataFrame(columns=[])\n",
    "result_perception_r_confusions = pd.DataFrame(columns=[])\n",
    "\n",
    "for CurrSub in AllSubjects: \n",
    "\n",
    "    sub = \"sub-1%02d\" % (CurrSub)\n",
    "    #print(sub)\n",
    "    sub2 = 's%d' % (CurrSub)\n",
    "    \n",
    "    Correct_minus_Incorrect_Details = EpisodicDetails_Correct.loc[:, [sub2]]-EpisodicDetails_Incorrect.loc[:, [sub2]]\n",
    "    Correct_minus_Incorrect_Rituals = Rituals_Correct.loc[:, [sub2]]-Rituals_Incorrect.loc[:, [sub2]] \n",
    "    Correct_minus_Incorrect_Confusions = EpisodicDetails_withinSchemaConfusions.loc[:, [sub2]]-EpisodicDetails_acrossSchemaConfusions.loc[:, [sub2]] \n",
    "    \n",
    "    result_perception_tmp = pd.DataFrame(columns=[])\n",
    "    result_perception_tmp_subj = pd.DataFrame(columns=[])\n",
    "    \n",
    "    for currLoop in range(12): # loop over 12 weddings\n",
    "        \n",
    "        result_perception_averageCurrLoop = pd.DataFrame(columns=[])\n",
    "        \n",
    "        #append event2\n",
    "        result_perception_tmp = result_perception_tmp.append(pd.Series(dictionary_with_info_perception[sub][str(currLoop)]['2'],name=currLoop))\n",
    "        result_perception_averageCurrLoop = result_perception_averageCurrLoop.append(pd.Series(dictionary_with_info_perception[sub][str(currLoop)]['2'],name=currLoop))\n",
    "\n",
    "        #append event3\n",
    "        result_perception_tmp = result_perception_tmp.append(pd.Series(dictionary_with_info_perception[sub][str(currLoop)]['3'],name=currLoop))\n",
    "        result_perception_averageCurrLoop = result_perception_averageCurrLoop.append(pd.Series(dictionary_with_info_perception[sub][str(currLoop)]['3'],name=currLoop))\n",
    "\n",
    "        #append event4\n",
    "        result_perception_tmp = result_perception_tmp.append(pd.Series(dictionary_with_info_perception[sub][str(currLoop)]['4'],name=currLoop))\n",
    "        result_perception_averageCurrLoop = result_perception_averageCurrLoop.append(pd.Series(dictionary_with_info_perception[sub][str(currLoop)]['4'],name=currLoop))\n",
    "\n",
    "        result_perception_tmp_subj = result_perception_tmp_subj.append(pd.Series(result_perception_averageCurrLoop.mean(),name=currLoop))\n",
    "        \n",
    "    # append average (across event2/3/4) of subj to result_perception dataframe\n",
    "    \n",
    "    result_perception = result_perception.append(pd.Series(result_perception_tmp.mean(),name=CurrSub))\n",
    "\n",
    "    #within subj correlation\n",
    "    result_perception_r = result_perception_r.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Details,result_perception_tmp_subj)[0],name=CurrSub))\n",
    "    result_perception_r_rituals = result_perception_r_rituals.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Rituals,result_perception_tmp_subj)[0],name=CurrSub))\n",
    "    result_perception_r_confusions = result_perception_r_confusions.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Confusions,result_perception_tmp_subj)[0],name=CurrSub))\n",
    "\n",
    "#fisher z transform before t test\n",
    "result_perception_r_fisherz = np.arctanh(result_perception_r)\n",
    "result_perception_r_rituals_fisherz = np.arctanh(result_perception_r_rituals)\n",
    "result_perception_r_confusions_fisherz = np.arctanh(result_perception_r_confusions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_perception_ttest_nullDistribution = pd.DataFrame(columns=[])\n",
    "result_perception_ttest_rituals_nullDistribution = pd.DataFrame(columns=[])\n",
    "result_perception_ttest_confusions_nullDistribution = pd.DataFrame(columns=[])\n",
    "\n",
    "for currIter in range(1000): \n",
    "\n",
    "    print(currIter)\n",
    "    \n",
    "    shuffle_tmp = pd.DataFrame(columns=[])\n",
    "    shuffle_tmp2 = pd.DataFrame(columns=[])\n",
    "    shuffle_tmp3 = pd.DataFrame(columns=[])\n",
    "\n",
    "    for CurrSub in AllSubjects: \n",
    "\n",
    "        sub = \"sub-1%02d\" % (CurrSub)\n",
    "        #print(sub)\n",
    "        sub2 = 's%d' % (CurrSub)\n",
    "\n",
    "        Correct_minus_Incorrect_Details = EpisodicDetails_Correct.loc[:, [sub2]]-EpisodicDetails_Incorrect.loc[:, [sub2]] \n",
    "        Correct_minus_Incorrect_Rituals = Rituals_Correct.loc[:, [sub2]]-Rituals_Incorrect.loc[:, [sub2]]\n",
    "        Correct_minus_Incorrect_Confusions = EpisodicDetails_withinSchemaConfusions.loc[:, [sub2]]-EpisodicDetails_acrossSchemaConfusions.loc[:, [sub2]] \n",
    "    \n",
    "   \n",
    "        result_perception_tmp = pd.DataFrame(columns=[])\n",
    "        result_perception_tmp_subj = pd.DataFrame(columns=[])\n",
    "\n",
    "        for currLoop in range(12): # loop over 12 weddings\n",
    "\n",
    "            result_perception_averageCurrLoop = pd.DataFrame(columns=[])\n",
    "\n",
    "            #append event2\n",
    "            result_perception_tmp = result_perception_tmp.append(pd.Series(dictionary_with_info_perception[sub][str(currLoop)]['2'],name=currLoop))\n",
    "            result_perception_averageCurrLoop = result_perception_averageCurrLoop.append(pd.Series(dictionary_with_info_perception[sub][str(currLoop)]['2'],name=currLoop))\n",
    "            \n",
    "            #append event3\n",
    "            result_perception_tmp = result_perception_tmp.append(pd.Series(dictionary_with_info_perception[sub][str(currLoop)]['3'],name=currLoop))\n",
    "            result_perception_averageCurrLoop = result_perception_averageCurrLoop.append(pd.Series(dictionary_with_info_perception[sub][str(currLoop)]['3'],name=currLoop))\n",
    "\n",
    "            #append event4\n",
    "            result_perception_tmp = result_perception_tmp.append(pd.Series(dictionary_with_info_perception[sub][str(currLoop)]['4'],name=currLoop))\n",
    "            result_perception_averageCurrLoop = result_perception_averageCurrLoop.append(pd.Series(dictionary_with_info_perception[sub][str(currLoop)]['4'],name=currLoop))\n",
    "\n",
    "            result_perception_tmp_subj = result_perception_tmp_subj.append(pd.Series(result_perception_averageCurrLoop.mean(),name=currLoop))\n",
    "\n",
    "        ## create null distribution by shuffling behavioral scores of 12 weddings within subj and then run correlation, 1000 times\n",
    "        Correct_minus_Incorrect_Details_shuffle = shuffle(Correct_minus_Incorrect_Details)\n",
    "        Correct_minus_Incorrect_Details_shuffle = Correct_minus_Incorrect_Details_shuffle.to_numpy()\n",
    "        shuffle_tmp = shuffle_tmp.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Details_shuffle,result_perception_tmp_subj)[0],name=CurrSub))\n",
    "\n",
    "        Correct_minus_Incorrect_Rituals_shuffle = shuffle(Correct_minus_Incorrect_Rituals)\n",
    "        Correct_minus_Incorrect_Rituals_shuffle = Correct_minus_Incorrect_Rituals_shuffle.to_numpy()\n",
    "        shuffle_tmp2 = shuffle_tmp2.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Rituals_shuffle,result_perception_tmp_subj)[0],name=CurrSub))\n",
    "        \n",
    "        Correct_minus_Incorrect_Confusions_shuffle = shuffle(Correct_minus_Incorrect_Confusions)\n",
    "        Correct_minus_Incorrect_Confusions_shuffle = Correct_minus_Incorrect_Confusions_shuffle.to_numpy()\n",
    "        shuffle_tmp3 = shuffle_tmp2.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Confusions_shuffle,result_perception_tmp_subj)[0],name=CurrSub))\n",
    "\n",
    "\n",
    "    #fisher z transform before t test\n",
    "    shuffle_tmp_fisherz = np.arctanh(shuffle_tmp)\n",
    "    shuffle_tmp2_fisherz = np.arctanh(shuffle_tmp2)\n",
    "    shuffle_tmp3_fisherz = np.arctanh(shuffle_tmp3)\n",
    "\n",
    "    result_perception_ttest_nullDistribution = result_perception_ttest_nullDistribution.append(pd.Series(stats.ttest_1samp(shuffle_tmp_fisherz,popmean=0)[0],name=currIter))\n",
    "    result_perception_ttest_rituals_nullDistribution = result_perception_ttest_rituals_nullDistribution.append(pd.Series(stats.ttest_1samp(shuffle_tmp2_fisherz,popmean=0)[0],name=currIter))\n",
    "\n",
    "    result_perception_ttest_confusions_nullDistribution = result_perception_ttest_confusions_nullDistribution.append(pd.Series(stats.ttest_1samp(shuffle_tmp3_fisherz,popmean=0)[0],name=currIter))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_perception_ttest_nullDistribution.to_csv('result_perception_ttest_nullDistribution_NEW.csv')\n",
    "result_perception_ttest_rituals_nullDistribution.to_csv('result_perception_ttest_rituals_nullDistribution_NEW.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the mean and sem of the R values\n",
    "\n",
    "print('mean r (details)', result_perception_r_fisherz.mean())\n",
    "print('sem r (details)', result_perception_r_fisherz.sem())\n",
    "\n",
    "print('mean r (rituals)', result_perception_r_rituals_fisherz.mean())\n",
    "print('sem r (rituals)', result_perception_r_rituals_fisherz.sem())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot null distribution details\n",
    "x = np.arange(0,1000,1)\n",
    "y = result_perception_ttest_nullDistribution[0].to_numpy()\n",
    "y = np.reshape(y, (-1,))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(y,bins=100)\n",
    "plt.axvline(stats.ttest_1samp(result_perception_r_fisherz,popmean=0)[0],color='r')\n",
    "\n",
    "print('instances above red line:', np.count_nonzero(y > stats.ttest_1samp(result_perception_r_fisherz,popmean=0)[0]))\n",
    "print('p val from distribution:', np.count_nonzero(y > stats.ttest_1samp(result_perception_r_fisherz,popmean=0)[0]) / len(y))\n",
    "\n",
    "s = 'p = ' + str(np.count_nonzero(y > stats.ttest_1samp(result_perception_r_fisherz,popmean=0)[0]) / len(y))\n",
    "\n",
    "plt.text(-3,35,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot null distribution rituals\n",
    "x = np.arange(0,1000,1)\n",
    "y = result_perception_ttest_rituals_nullDistribution[0].to_numpy()\n",
    "y = np.reshape(y, (-1,))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(y,bins=100)\n",
    "plt.axvline(stats.ttest_1samp(result_perception_r_rituals_fisherz,popmean=0)[0],color='r')\n",
    "\n",
    "print('instances above red line:', np.count_nonzero(y > stats.ttest_1samp(result_perception_r_rituals_fisherz,popmean=0)[0]))\n",
    "print('p val from distribution:', np.count_nonzero(y > stats.ttest_1samp(result_perception_r_rituals_fisherz,popmean=0)[0]) / len(y))\n",
    "\n",
    "s = 'p = ' + str(np.count_nonzero(y > stats.ttest_1samp(result_perception_r_rituals_fisherz,popmean=0)[0]) / len(y))\n",
    "\n",
    "plt.text(-3,35,s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rotated minus perception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_rotated = pd.DataFrame(columns=[])\n",
    "result_rotated_r = pd.DataFrame(columns=[])\n",
    "result_rotated_r_rituals = pd.DataFrame(columns=[])\n",
    "\n",
    "for CurrSub in AllSubjects: \n",
    "\n",
    "    sub = \"sub-1%02d\" % (CurrSub)\n",
    "        #print(sub)\n",
    "    sub2 = 's%d' % (CurrSub)\n",
    "\n",
    "    Correct_minus_Incorrect_Details = EpisodicDetails_Correct.loc[:, [sub2]]-EpisodicDetails_Incorrect.loc[:, [sub2]] \n",
    "    Correct_minus_Incorrect_Rituals = Rituals_Correct.loc[:, [sub2]]-Rituals_Incorrect.loc[:, [sub2]] \n",
    "\n",
    "    result_rotated_tmp = pd.DataFrame(columns=[])\n",
    "    result_rotated_tmp_subj = pd.DataFrame(columns=[])\n",
    "    \n",
    "    for currLoop in range(12): # loop over 12 weddings\n",
    "\n",
    "        result_rotated_averageCurrLoop = pd.DataFrame(columns=[])\n",
    "        \n",
    "        #append event2\n",
    "        result_rotated_tmp = result_rotated_tmp.append(pd.Series(dictionary_with_info_rotatedminusperception[sub][str(currLoop)]['2'],name=currLoop))\n",
    "        result_rotated_averageCurrLoop = result_rotated_averageCurrLoop.append(pd.Series(dictionary_with_info_rotatedminusperception[sub][str(currLoop)]['2'],name=currLoop))\n",
    "\n",
    "        #append event3\n",
    "        result_rotated_tmp = result_rotated_tmp.append(pd.Series(dictionary_with_info_rotatedminusperception[sub][str(currLoop)]['3'],name=currLoop))\n",
    "        result_rotated_averageCurrLoop = result_rotated_averageCurrLoop.append(pd.Series(dictionary_with_info_rotatedminusperception[sub][str(currLoop)]['3'],name=currLoop))\n",
    "\n",
    "        result_rotated_tmp_subj = result_rotated_tmp_subj.append(pd.Series(result_rotated_averageCurrLoop.mean(),name=currLoop))\n",
    "        \n",
    "    # append average (across event2/3/4) of subj to rotated dataframe\n",
    "    \n",
    "    result_rotated = result_rotated.append(pd.Series(result_rotated_tmp.mean(),name=CurrSub))\n",
    "\n",
    "    #within subj correlation\n",
    "    result_rotated_r = result_rotated_r.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Details,result_rotated_tmp_subj)[0],name=CurrSub))\n",
    "    result_rotated_r_rituals = result_rotated_r_rituals.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Rituals,result_rotated_tmp_subj)[0],name=CurrSub))\n",
    "\n",
    "#fisher z transform before t test\n",
    "result_rotated_r_fisherz = np.arctanh(result_rotated_r)\n",
    "result_rotated_r_rituals_fisherz = np.arctanh(result_rotated_r_rituals)\n",
    "\n",
    "\n",
    "# correlate across-subjects\n",
    "print('across subject correlations:')\n",
    "print('schematest with rotated: ',stats.spearmanr(schematest['diffScore'],result_rotated))\n",
    "print('details with rotated: ',stats.spearmanr(recallBehav2,result_rotated))\n",
    "print('rituals with rotated: ',stats.spearmanr(recallBehav4,result_rotated))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## null distribution\n",
    "\n",
    "## ONLY RAN ONCE, THEN SAVED, CAN BE RELOADED WITH CODE BLOCK BELOW\n",
    "\n",
    "result_rotated_ttest_nullDistribution = pd.DataFrame(columns=[])\n",
    "result_rotated_ttest_rituals_nullDistribution = pd.DataFrame(columns=[])\n",
    "result_rotated_ttest_confusions_nullDistribution = pd.DataFrame(columns=[])\n",
    "\n",
    "for currIter in range(1000): \n",
    "\n",
    "    print(currIter)\n",
    "    \n",
    "    shuffle_tmp = pd.DataFrame(columns=[])\n",
    "    shuffle_tmp2 = pd.DataFrame(columns=[])\n",
    "    shuffle_tmp3 = pd.DataFrame(columns=[])\n",
    "\n",
    "    for CurrSub in AllSubjects: \n",
    "\n",
    "        sub = \"sub-1%02d\" % (CurrSub)\n",
    "        #print(sub)\n",
    "        sub2 = 's%d' % (CurrSub)\n",
    "\n",
    "        Correct_minus_Incorrect_Details = EpisodicDetails_Correct.loc[:, [sub2]]-EpisodicDetails_Incorrect.loc[:, [sub2]] \n",
    "        Correct_minus_Incorrect_Rituals = Rituals_Correct.loc[:, [sub2]]-Rituals_Incorrect.loc[:, [sub2]] \n",
    "   \n",
    "        result_rotated_tmp = pd.DataFrame(columns=[])\n",
    "        result_rotated_tmp_subj = pd.DataFrame(columns=[])\n",
    "\n",
    "        for currLoop in range(12): # loop over 12 weddings\n",
    "\n",
    "            result_rotated_averageCurrLoop = pd.DataFrame(columns=[])\n",
    "        \n",
    "        #append event2\n",
    "            result_rotated_tmp = result_rotated_tmp.append(pd.Series(dictionary_with_info_rotatedminusperception[sub][str(currLoop)]['2'],name=currLoop))\n",
    "            result_rotated_averageCurrLoop = result_rotated_averageCurrLoop.append(pd.Series(dictionary_with_info_rotatedminusperception[sub][str(currLoop)]['2'],name=currLoop))\n",
    "\n",
    "        #append event3\n",
    "            result_rotated_tmp = result_rotated_tmp.append(pd.Series(dictionary_with_info_rotatedminusperception[sub][str(currLoop)]['3'],name=currLoop))\n",
    "            result_rotated_averageCurrLoop = result_rotated_averageCurrLoop.append(pd.Series(dictionary_with_info_rotatedminusperception[sub][str(currLoop)]['3'],name=currLoop))\n",
    "\n",
    "        #append event4\n",
    "#            result_rotated_tmp = result_rotated_tmp.append(pd.Series(dictionary_with_info_rotated[sub][str(currLoop)]['4'],name=currLoop))\n",
    "#            result_rotated_averageCurrLoop = result_rotated_averageCurrLoop.append(pd.Series(dictionary_with_info_rotated[sub][str(currLoop)]['4'],name=currLoop))\n",
    "\n",
    "            result_rotated_tmp_subj = result_rotated_tmp_subj.append(pd.Series(result_rotated_averageCurrLoop.mean(),name=currLoop))\n",
    "        \n",
    "        ## create null distribution by shuffling behavioral scores of 12 weddings within subj and then run correlation, 1000 times\n",
    "        Correct_minus_Incorrect_Details_shuffle = shuffle(Correct_minus_Incorrect_Details)\n",
    "        Correct_minus_Incorrect_Details_shuffle = Correct_minus_Incorrect_Details_shuffle.to_numpy()\n",
    "        shuffle_tmp = shuffle_tmp.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Details_shuffle,result_rotated_tmp_subj)[0],name=CurrSub))\n",
    "\n",
    "        Correct_minus_Incorrect_Rituals_shuffle = shuffle(Correct_minus_Incorrect_Rituals)\n",
    "        Correct_minus_Incorrect_Rituals_shuffle = Correct_minus_Incorrect_Rituals_shuffle.to_numpy()\n",
    "        shuffle_tmp2 = shuffle_tmp2.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Rituals_shuffle,result_rotated_tmp_subj)[0],name=CurrSub))\n",
    "\n",
    "    #fisher z transform before t test\n",
    "    shuffle_tmp_fisherz = np.arctanh(shuffle_tmp)\n",
    "    shuffle_tmp2_fisherz = np.arctanh(shuffle_tmp2)\n",
    "    shuffle_tmp3_fisherz = np.arctanh(shuffle_tmp3)\n",
    "\n",
    "    result_rotated_ttest_nullDistribution = result_rotated_ttest_nullDistribution.append(pd.Series(stats.ttest_1samp(shuffle_tmp_fisherz,popmean=0)[0],name=currIter))\n",
    "    result_rotated_ttest_rituals_nullDistribution = result_rotated_ttest_rituals_nullDistribution.append(pd.Series(stats.ttest_1samp(shuffle_tmp2_fisherz,popmean=0)[0],name=currIter))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rotated_ttest_nullDistribution.to_csv('result_rotatedminusperception_ttest_nullDistributionNEW.csv')\n",
    "result_rotated_ttest_rituals_nullDistribution.to_csv('result_rotatedminusperception_ttest_rituals_nullDistributionNEW.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD NULL DISTRIBUTIONS (SINCE IT WAS ALREADY RAN AND SAVED)\n",
    "\n",
    "result_rotated_ttest_nullDistribution = pd.read_csv('/Users/silvycollin/Documents/GitHub/schema/final_code/roi_average_folder_Ross/result_rotatedminusperception_ttest_nullDistributionNEW.csv')\n",
    "result_rotated_ttest_rituals_nullDistribution = pd.read_csv('/Users/silvycollin/Documents/GitHub/schema/final_code/roi_average_folder_Ross/result_rotatedminusperception_ttest_rituals_nullDistributionNEW.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the mean and sem of the R values\n",
    "\n",
    "print('mean r (details)', result_rotated_r_fisherz.mean())\n",
    "print('sem r (details)', result_rotated_r_fisherz.sem())\n",
    "\n",
    "print('mean r (rituals)', result_rotated_r_rituals_fisherz.mean())\n",
    "print('sem r (rituals)', result_rotated_r_rituals_fisherz.sem())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot null distribution details\n",
    "x = np.arange(0,1000,1)\n",
    "y = result_rotated_ttest_nullDistribution['0'].to_numpy()\n",
    "y = np.reshape(y, (-1,))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(y,bins=100)\n",
    "plt.axvline(stats.ttest_1samp(result_rotated_r_fisherz,popmean=0)[0],color='r')\n",
    "\n",
    "print('instances above red line:', np.count_nonzero(y > stats.ttest_1samp(result_rotated_r_fisherz,popmean=0)[0]))\n",
    "print('p val from distribution:', np.count_nonzero(y > stats.ttest_1samp(result_rotated_r_fisherz,popmean=0)[0]) / len(y))\n",
    "\n",
    "s = 'p = ' + str(np.count_nonzero(y > stats.ttest_1samp(result_rotated_r_fisherz,popmean=0)[0]) / len(y))\n",
    "\n",
    "plt.text(-3,35,s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot null distribution rituals\n",
    "x = np.arange(0,1000,1)\n",
    "y = result_rotated_ttest_rituals_nullDistribution['0'].to_numpy()\n",
    "y = np.reshape(y, (-1,))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(y,bins=100)\n",
    "plt.axvline(stats.ttest_1samp(result_rotated_r_rituals_fisherz,popmean=0)[0],color='r')\n",
    "\n",
    "print('instances above red line:', np.count_nonzero(y > stats.ttest_1samp(result_rotated_r_rituals_fisherz,popmean=0)[0]))\n",
    "print('p val from distribution:', np.count_nonzero(y > stats.ttest_1samp(result_rotated_r_rituals_fisherz,popmean=0)[0]) / len(y))\n",
    "\n",
    "s = 'p = ' + str(np.count_nonzero(y > stats.ttest_1samp(result_rotated_r_rituals_fisherz,popmean=0)[0]) / len(y))\n",
    "\n",
    "plt.text(-3,35,s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# perception minus rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_perception = pd.DataFrame(columns=[])\n",
    "result_perception_r = pd.DataFrame(columns=[])\n",
    "result_perception_r_rituals = pd.DataFrame(columns=[])\n",
    "result_perception_r_confusions = pd.DataFrame(columns=[])\n",
    "\n",
    "for CurrSub in AllSubjects: \n",
    "\n",
    "    sub = \"sub-1%02d\" % (CurrSub)\n",
    "    #print(sub)\n",
    "    sub2 = 's%d' % (CurrSub)\n",
    "    \n",
    "    Correct_minus_Incorrect_Details = EpisodicDetails_Correct.loc[:, [sub2]]-EpisodicDetails_Incorrect.loc[:, [sub2]]\n",
    "    Correct_minus_Incorrect_Rituals = Rituals_Correct.loc[:, [sub2]]-Rituals_Incorrect.loc[:, [sub2]] \n",
    "    Correct_minus_Incorrect_Confusions = EpisodicDetails_withinSchemaConfusions.loc[:, [sub2]]-EpisodicDetails_acrossSchemaConfusions.loc[:, [sub2]] \n",
    "    \n",
    "    result_perception_tmp = pd.DataFrame(columns=[])\n",
    "    result_perception_tmp_subj = pd.DataFrame(columns=[])\n",
    "    \n",
    "    for currLoop in range(12): # loop over 12 weddings\n",
    "        \n",
    "        result_perception_averageCurrLoop = pd.DataFrame(columns=[])\n",
    "        \n",
    "        #append event2\n",
    "        result_perception_tmp = result_perception_tmp.append(pd.Series(dictionary_with_info_perceptionminusrotated[sub][str(currLoop)]['2'],name=currLoop))\n",
    "        result_perception_averageCurrLoop = result_perception_averageCurrLoop.append(pd.Series(dictionary_with_info_perceptionminusrotated[sub][str(currLoop)]['2'],name=currLoop))\n",
    "\n",
    "        #append event3\n",
    "        result_perception_tmp = result_perception_tmp.append(pd.Series(dictionary_with_info_perceptionminusrotated[sub][str(currLoop)]['3'],name=currLoop))\n",
    "        result_perception_averageCurrLoop = result_perception_averageCurrLoop.append(pd.Series(dictionary_with_info_perceptionminusrotated[sub][str(currLoop)]['3'],name=currLoop))\n",
    "\n",
    "        #append event4\n",
    "        result_perception_tmp = result_perception_tmp.append(pd.Series(dictionary_with_info_perceptionminusrotated[sub][str(currLoop)]['4'],name=currLoop))\n",
    "        result_perception_averageCurrLoop = result_perception_averageCurrLoop.append(pd.Series(dictionary_with_info_perceptionminusrotated[sub][str(currLoop)]['4'],name=currLoop))\n",
    "\n",
    "        result_perception_tmp_subj = result_perception_tmp_subj.append(pd.Series(result_perception_averageCurrLoop.mean(),name=currLoop))\n",
    "        \n",
    "    # append average (across event2/3/4) of subj to result_perception dataframe\n",
    "    \n",
    "    result_perception = result_perception.append(pd.Series(result_perception_tmp.mean(),name=CurrSub))\n",
    "\n",
    "    #within subj correlation\n",
    "    result_perception_r = result_perception_r.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Details,result_perception_tmp_subj)[0],name=CurrSub))\n",
    "    result_perception_r_rituals = result_perception_r_rituals.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Rituals,result_perception_tmp_subj)[0],name=CurrSub))\n",
    "    result_perception_r_confusions = result_perception_r_confusions.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Confusions,result_perception_tmp_subj)[0],name=CurrSub))\n",
    "\n",
    "#fisher z transform before t test\n",
    "result_perception_r_fisherz = np.arctanh(result_perception_r)\n",
    "result_perception_r_rituals_fisherz = np.arctanh(result_perception_r_rituals)\n",
    "result_perception_r_confusions_fisherz = np.arctanh(result_perception_r_confusions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_perception_ttest_nullDistribution = pd.DataFrame(columns=[])\n",
    "result_perception_ttest_rituals_nullDistribution = pd.DataFrame(columns=[])\n",
    "result_perception_ttest_confusions_nullDistribution = pd.DataFrame(columns=[])\n",
    "\n",
    "for currIter in range(1000): \n",
    "\n",
    "    print(currIter)\n",
    "    \n",
    "    shuffle_tmp = pd.DataFrame(columns=[])\n",
    "    shuffle_tmp2 = pd.DataFrame(columns=[])\n",
    "    shuffle_tmp3 = pd.DataFrame(columns=[])\n",
    "\n",
    "    for CurrSub in AllSubjects: \n",
    "\n",
    "        sub = \"sub-1%02d\" % (CurrSub)\n",
    "        #print(sub)\n",
    "        sub2 = 's%d' % (CurrSub)\n",
    "\n",
    "        Correct_minus_Incorrect_Details = EpisodicDetails_Correct.loc[:, [sub2]]-EpisodicDetails_Incorrect.loc[:, [sub2]] \n",
    "        Correct_minus_Incorrect_Rituals = Rituals_Correct.loc[:, [sub2]]-Rituals_Incorrect.loc[:, [sub2]]\n",
    "        Correct_minus_Incorrect_Confusions = EpisodicDetails_withinSchemaConfusions.loc[:, [sub2]]-EpisodicDetails_acrossSchemaConfusions.loc[:, [sub2]] \n",
    "    \n",
    "   \n",
    "        result_perception_tmp = pd.DataFrame(columns=[])\n",
    "        result_perception_tmp_subj = pd.DataFrame(columns=[])\n",
    "\n",
    "        for currLoop in range(12): # loop over 12 weddings\n",
    "\n",
    "            result_perception_averageCurrLoop = pd.DataFrame(columns=[])\n",
    "\n",
    "            #append event2\n",
    "            result_perception_tmp = result_perception_tmp.append(pd.Series(dictionary_with_info_perceptionminusrotated[sub][str(currLoop)]['2'],name=currLoop))\n",
    "            result_perception_averageCurrLoop = result_perception_averageCurrLoop.append(pd.Series(dictionary_with_info_perceptionminusrotated[sub][str(currLoop)]['2'],name=currLoop))\n",
    "            \n",
    "            #append event3\n",
    "            result_perception_tmp = result_perception_tmp.append(pd.Series(dictionary_with_info_perceptionminusrotated[sub][str(currLoop)]['3'],name=currLoop))\n",
    "            result_perception_averageCurrLoop = result_perception_averageCurrLoop.append(pd.Series(dictionary_with_info_perceptionminusrotated[sub][str(currLoop)]['3'],name=currLoop))\n",
    "\n",
    "            #append event4\n",
    "            result_perception_tmp = result_perception_tmp.append(pd.Series(dictionary_with_info_perceptionminusrotated[sub][str(currLoop)]['4'],name=currLoop))\n",
    "            result_perception_averageCurrLoop = result_perception_averageCurrLoop.append(pd.Series(dictionary_with_info_perceptionminusrotated[sub][str(currLoop)]['4'],name=currLoop))\n",
    "\n",
    "            result_perception_tmp_subj = result_perception_tmp_subj.append(pd.Series(result_perception_averageCurrLoop.mean(),name=currLoop))\n",
    "\n",
    "        ## create null distribution by shuffling behavioral scores of 12 weddings within subj and then run correlation, 1000 times\n",
    "        Correct_minus_Incorrect_Details_shuffle = shuffle(Correct_minus_Incorrect_Details)\n",
    "        Correct_minus_Incorrect_Details_shuffle = Correct_minus_Incorrect_Details_shuffle.to_numpy()\n",
    "        shuffle_tmp = shuffle_tmp.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Details_shuffle,result_perception_tmp_subj)[0],name=CurrSub))\n",
    "\n",
    "        Correct_minus_Incorrect_Rituals_shuffle = shuffle(Correct_minus_Incorrect_Rituals)\n",
    "        Correct_minus_Incorrect_Rituals_shuffle = Correct_minus_Incorrect_Rituals_shuffle.to_numpy()\n",
    "        shuffle_tmp2 = shuffle_tmp2.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Rituals_shuffle,result_perception_tmp_subj)[0],name=CurrSub))\n",
    "        \n",
    "        Correct_minus_Incorrect_Confusions_shuffle = shuffle(Correct_minus_Incorrect_Confusions)\n",
    "        Correct_minus_Incorrect_Confusions_shuffle = Correct_minus_Incorrect_Confusions_shuffle.to_numpy()\n",
    "        shuffle_tmp3 = shuffle_tmp2.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Confusions_shuffle,result_perception_tmp_subj)[0],name=CurrSub))\n",
    "\n",
    "\n",
    "    #fisher z transform before t test\n",
    "    shuffle_tmp_fisherz = np.arctanh(shuffle_tmp)\n",
    "    shuffle_tmp2_fisherz = np.arctanh(shuffle_tmp2)\n",
    "    shuffle_tmp3_fisherz = np.arctanh(shuffle_tmp3)\n",
    "\n",
    "    result_perception_ttest_nullDistribution = result_perception_ttest_nullDistribution.append(pd.Series(stats.ttest_1samp(shuffle_tmp_fisherz,popmean=0)[0],name=currIter))\n",
    "    result_perception_ttest_rituals_nullDistribution = result_perception_ttest_rituals_nullDistribution.append(pd.Series(stats.ttest_1samp(shuffle_tmp2_fisherz,popmean=0)[0],name=currIter))\n",
    "\n",
    "    result_perception_ttest_confusions_nullDistribution = result_perception_ttest_confusions_nullDistribution.append(pd.Series(stats.ttest_1samp(shuffle_tmp3_fisherz,popmean=0)[0],name=currIter))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_perception_ttest_nullDistribution.to_csv('result_perception_ttest_nullDistribution_NEW.csv')\n",
    "result_perception_ttest_rituals_nullDistribution.to_csv('result_perception_ttest_rituals_nullDistribution_NEW.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the mean and sem of the R values\n",
    "\n",
    "print('mean r (details)', result_perception_r_fisherz.mean())\n",
    "print('sem r (details)', result_perception_r_fisherz.sem())\n",
    "\n",
    "print('mean r (rituals)', result_perception_r_rituals_fisherz.mean())\n",
    "print('sem r (rituals)', result_perception_r_rituals_fisherz.sem())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot null distribution details\n",
    "x = np.arange(0,1000,1)\n",
    "y = result_perception_ttest_nullDistribution[0].to_numpy()\n",
    "y = np.reshape(y, (-1,))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(y,bins=100)\n",
    "plt.axvline(stats.ttest_1samp(result_perception_r_fisherz,popmean=0)[0],color='r')\n",
    "\n",
    "print('instances above red line:', np.count_nonzero(y > stats.ttest_1samp(result_perception_r_fisherz,popmean=0)[0]))\n",
    "print('p val from distribution:', np.count_nonzero(y > stats.ttest_1samp(result_perception_r_fisherz,popmean=0)[0]) / len(y))\n",
    "\n",
    "s = 'p = ' + str(np.count_nonzero(y > stats.ttest_1samp(result_perception_r_fisherz,popmean=0)[0]) / len(y))\n",
    "\n",
    "plt.text(-3,35,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot null distribution rituals\n",
    "x = np.arange(0,1000,1)\n",
    "y = result_perception_ttest_rituals_nullDistribution[0].to_numpy()\n",
    "y = np.reshape(y, (-1,))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(y,bins=100)\n",
    "plt.axvline(stats.ttest_1samp(result_perception_r_rituals_fisherz,popmean=0)[0],color='r')\n",
    "\n",
    "print('instances above red line:', np.count_nonzero(y > stats.ttest_1samp(result_perception_r_rituals_fisherz,popmean=0)[0]))\n",
    "print('p val from distribution:', np.count_nonzero(y > stats.ttest_1samp(result_perception_r_rituals_fisherz,popmean=0)[0]) / len(y))\n",
    "\n",
    "s = 'p = ' + str(np.count_nonzero(y > stats.ttest_1samp(result_perception_r_rituals_fisherz,popmean=0)[0]) / len(y))\n",
    "\n",
    "plt.text(-3,35,s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rotated and perception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_rotated = pd.DataFrame(columns=[])\n",
    "result_rotated_r = pd.DataFrame(columns=[])\n",
    "result_rotated_r_rituals = pd.DataFrame(columns=[])\n",
    "\n",
    "for CurrSub in AllSubjects: \n",
    "\n",
    "    sub = \"sub-1%02d\" % (CurrSub)\n",
    "        #print(sub)\n",
    "    sub2 = 's%d' % (CurrSub)\n",
    "\n",
    "    Correct_minus_Incorrect_Details = EpisodicDetails_Correct.loc[:, [sub2]]-EpisodicDetails_Incorrect.loc[:, [sub2]] \n",
    "    Correct_minus_Incorrect_Rituals = Rituals_Correct.loc[:, [sub2]]-Rituals_Incorrect.loc[:, [sub2]] \n",
    "\n",
    "    result_rotated_tmp = pd.DataFrame(columns=[])\n",
    "    result_rotated_tmp_subj = pd.DataFrame(columns=[])\n",
    "    \n",
    "    for currLoop in range(12): # loop over 12 weddings\n",
    "\n",
    "        result_rotated_averageCurrLoop = pd.DataFrame(columns=[])\n",
    "        \n",
    "        #append event2\n",
    "        result_rotated_tmp = pd.concat([result_rotated_tmp, pd.Series(dictionary_with_info_rotatedandperception[sub][str(currLoop)]['2'])])\n",
    "        result_rotated_averageCurrLoop = pd.concat([result_rotated_averageCurrLoop, pd.Series(dictionary_with_info_rotatedandperception[sub][str(currLoop)]['2'])])\n",
    "        #result_rotated_tmp = result_rotated_tmp.append(pd.Series(dictionary_with_info_rotatedandperception[sub][str(currLoop)]['2'],name=currLoop))\n",
    "        #result_rotated_averageCurrLoop = result_rotated_averageCurrLoop.append(pd.Series(dictionary_with_info_rotatedandperception[sub][str(currLoop)]['2'],name=currLoop))\n",
    "\n",
    "        #append event3\n",
    "        result_rotated_tmp = pd.concat([result_rotated_tmp, pd.Series(dictionary_with_info_rotatedandperception[sub][str(currLoop)]['3'])])\n",
    "        result_rotated_averageCurrLoop = pd.concat([result_rotated_averageCurrLoop, pd.Series(dictionary_with_info_rotatedandperception[sub][str(currLoop)]['3'])]) \n",
    "        #result_rotated_tmp = result_rotated_tmp.append(pd.Series(dictionary_with_info_rotatedandperception[sub][str(currLoop)]['3'],name=currLoop))\n",
    "        #result_rotated_averageCurrLoop = result_rotated_averageCurrLoop.append(pd.Series(dictionary_with_info_rotatedandperception[sub][str(currLoop)]['3'],name=currLoop))\n",
    "\n",
    "        #append event4\n",
    "#         result_rotated_tmp = result_rotated_tmp.append(pd.Series(dictionary_with_info_rotatedandperception[sub][str(currLoop)]['4'],name=currLoop))\n",
    "#         result_rotated_averageCurrLoop = result_rotated_averageCurrLoop.append(pd.Series(dictionary_with_info_rotatedandperception[sub][str(currLoop)]['4'],name=currLoop))\n",
    "        \n",
    "#        result_rotated_tmp_subj = result_rotated_tmp_subj.append(pd.Series(result_rotated_averageCurrLoop.mean(),name=currLoop))\n",
    "        result_rotated_tmp_subj = pd.concat([result_rotated_tmp_subj, pd.Series(result_rotated_averageCurrLoop.mean())])\n",
    "               \n",
    "    # append average (across event2/3/4) of subj to rotated dataframe\n",
    "    \n",
    "#    result_rotated = result_rotated.append(pd.Series(result_rotated_tmp.mean(),name=CurrSub))\n",
    "    result_rotated = pd.concat([result_rotated, pd.Series(result_rotated_tmp.mean())])\n",
    "    \n",
    "    #within subj correlation\n",
    "#    result_rotated_r = result_rotated_r.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Details,result_rotated_tmp_subj)[0],name=CurrSub))\n",
    "#    result_rotated_r_rituals = result_rotated_r_rituals.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Rituals,result_rotated_tmp_subj)[0],name=CurrSub))\n",
    "\n",
    "    result_rotated_r = pd.concat([result_rotated_r, pd.Series(stats.spearmanr(Correct_minus_Incorrect_Details,result_rotated_tmp_subj)[0])])\n",
    "    result_rotated_r_rituals = pd.concat([result_rotated_r_rituals, pd.Series(stats.spearmanr(Correct_minus_Incorrect_Rituals,result_rotated_tmp_subj)[0])])\n",
    "\n",
    "#fisher z transform before t test\n",
    "result_rotatedandperception_r_fisherz = np.arctanh(result_rotated_r)\n",
    "result_rotatedandperception_r_rituals_fisherz = np.arctanh(result_rotated_r_rituals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the mean and sem of the R values\n",
    "\n",
    "print('mean r (details)', result_rotatedandperception_r_fisherz.mean())\n",
    "print('sem r (details)', result_rotatedandperception_r_fisherz.sem())\n",
    "\n",
    "print('mean r (rituals)', result_rotatedandperception_r_rituals_fisherz.mean())\n",
    "print('sem r (rituals)', result_rotatedandperception_r_rituals_fisherz.sem())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## null distribution\n",
    "\n",
    "## ONLY RAN ONCE, THEN SAVED, CAN BE RELOADED WITH CODE BLOCK BELOW\n",
    "\n",
    "result_rotated_ttest_nullDistribution = pd.DataFrame(columns=[])\n",
    "result_rotated_ttest_rituals_nullDistribution = pd.DataFrame(columns=[])\n",
    "result_rotated_ttest_confusions_nullDistribution = pd.DataFrame(columns=[])\n",
    "\n",
    "for currIter in range(1000): \n",
    "\n",
    "    print(currIter)\n",
    "    \n",
    "    shuffle_tmp = pd.DataFrame(columns=[])\n",
    "    shuffle_tmp2 = pd.DataFrame(columns=[])\n",
    "    shuffle_tmp3 = pd.DataFrame(columns=[])\n",
    "\n",
    "    for CurrSub in AllSubjects: \n",
    "\n",
    "        sub = \"sub-1%02d\" % (CurrSub)\n",
    "        #print(sub)\n",
    "        sub2 = 's%d' % (CurrSub)\n",
    "\n",
    "        Correct_minus_Incorrect_Details = EpisodicDetails_Correct.loc[:, [sub2]]-EpisodicDetails_Incorrect.loc[:, [sub2]] \n",
    "        Correct_minus_Incorrect_Rituals = Rituals_Correct.loc[:, [sub2]]-Rituals_Incorrect.loc[:, [sub2]] \n",
    "   \n",
    "        result_rotated_tmp = pd.DataFrame(columns=[])\n",
    "        result_rotated_tmp_subj = pd.DataFrame(columns=[])\n",
    "\n",
    "        for currLoop in range(12): # loop over 12 weddings\n",
    "\n",
    "            result_rotated_averageCurrLoop = pd.DataFrame(columns=[])\n",
    "        \n",
    "        #append event2\n",
    "            result_rotated_tmp = result_rotated_tmp.append(pd.Series(dictionary_with_info_rotatedandperception[sub][str(currLoop)]['2'],name=currLoop))\n",
    "            result_rotated_averageCurrLoop = result_rotated_averageCurrLoop.append(pd.Series(dictionary_with_info_rotatedandperception[sub][str(currLoop)]['2'],name=currLoop))\n",
    "\n",
    "        #append event3\n",
    "            result_rotated_tmp = result_rotated_tmp.append(pd.Series(dictionary_with_info_rotatedandperception[sub][str(currLoop)]['3'],name=currLoop))\n",
    "            result_rotated_averageCurrLoop = result_rotated_averageCurrLoop.append(pd.Series(dictionary_with_info_rotatedandperception[sub][str(currLoop)]['3'],name=currLoop))\n",
    "\n",
    "            result_rotated_tmp_subj = result_rotated_tmp_subj.append(pd.Series(result_rotated_averageCurrLoop.mean(),name=currLoop))\n",
    "        \n",
    "        ## create null distribution by shuffling behavioral scores of 12 weddings within subj and then run correlation, 1000 times\n",
    "        Correct_minus_Incorrect_Details_shuffle = shuffle(Correct_minus_Incorrect_Details)\n",
    "        Correct_minus_Incorrect_Details_shuffle = Correct_minus_Incorrect_Details_shuffle.to_numpy()\n",
    "        shuffle_tmp = shuffle_tmp.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Details_shuffle,result_rotated_tmp_subj)[0],name=CurrSub))\n",
    "\n",
    "        Correct_minus_Incorrect_Rituals_shuffle = shuffle(Correct_minus_Incorrect_Rituals)\n",
    "        Correct_minus_Incorrect_Rituals_shuffle = Correct_minus_Incorrect_Rituals_shuffle.to_numpy()\n",
    "        shuffle_tmp2 = shuffle_tmp2.append(pd.Series(stats.spearmanr(Correct_minus_Incorrect_Rituals_shuffle,result_rotated_tmp_subj)[0],name=CurrSub))\n",
    "\n",
    "    #fisher z transform before t test\n",
    "    shuffle_tmp_fisherz = np.arctanh(shuffle_tmp)\n",
    "    shuffle_tmp2_fisherz = np.arctanh(shuffle_tmp2)\n",
    "    shuffle_tmp3_fisherz = np.arctanh(shuffle_tmp3)\n",
    "\n",
    "    result_rotated_ttest_nullDistribution = result_rotated_ttest_nullDistribution.append(pd.Series(stats.ttest_1samp(shuffle_tmp_fisherz,popmean=0)[0],name=currIter))\n",
    "    result_rotated_ttest_rituals_nullDistribution = result_rotated_ttest_rituals_nullDistribution.append(pd.Series(stats.ttest_1samp(shuffle_tmp2_fisherz,popmean=0)[0],name=currIter))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rotated_ttest_nullDistribution.to_csv('result_rotatedandperception_ttest_nullDistributionNEW.csv')\n",
    "result_rotated_ttest_rituals_nullDistribution.to_csv('result_rotatedandperception_ttest_rituals_nullDistributionNEW.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD NULL DISTRIBUTIONS (SINCE IT WAS ALREADY RAN AND SAVED)\n",
    "\n",
    "result_rotated_ttest_nullDistribution = pd.read_csv('/Users/silvycollin/Documents/GitHub/schema/final_code/roi_average_folder_Ross/result_rotatedandperception_ttest_nullDistributionNEW.csv')\n",
    "result_rotated_ttest_rituals_nullDistribution = pd.read_csv('/Users/silvycollin/Documents/GitHub/schema/final_code/roi_average_folder_Ross/result_rotatedandperception_ttest_rituals_nullDistributionNEW.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot null distribution details\n",
    "x = np.arange(0,1000,1)\n",
    "y = result_rotated_ttest_nullDistribution[0].to_numpy()#['0'].to_numpy()\n",
    "y = np.reshape(y, (-1,))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(y,bins=100)\n",
    "plt.axvline(stats.ttest_1samp(result_rotatedandperception_r_fisherz,popmean=0)[0],color='r')\n",
    "\n",
    "print('instances above red line:', np.count_nonzero(y > stats.ttest_1samp(result_rotatedandperception_r_fisherz,popmean=0)[0]))\n",
    "print('p val from distribution:', np.count_nonzero(y > stats.ttest_1samp(result_rotatedandperception_r_fisherz,popmean=0)[0]) / len(y))\n",
    "\n",
    "s = 'p = ' + str(np.count_nonzero(y > stats.ttest_1samp(result_rotatedandperception_r_fisherz,popmean=0)[0]) / len(y))\n",
    "\n",
    "plt.text(-3,35,s)\n",
    "\n",
    "# plt.savefig('details_vs_rotatedStrength_tscores_to_nullNEW.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot null distribution rituals\n",
    "x = np.arange(0,1000,1)\n",
    "y = result_rotated_ttest_rituals_nullDistribution[0].to_numpy()\n",
    "y = np.reshape(y, (-1,))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(y,bins=100)\n",
    "plt.axvline(stats.ttest_1samp(result_rotatedandperception_r_rituals_fisherz,popmean=0)[0],color='r')\n",
    "\n",
    "print('instances above red line:', np.count_nonzero(y > stats.ttest_1samp(result_rotatedandperception_r_rituals_fisherz,popmean=0)[0]))\n",
    "print('p val from distribution:', np.count_nonzero(y > stats.ttest_1samp(result_rotatedandperception_r_rituals_fisherz,popmean=0)[0]) / len(y))\n",
    "\n",
    "s = 'p = ' + str(np.count_nonzero(y > stats.ttest_1samp(result_rotatedandperception_r_rituals_fisherz,popmean=0)[0]) / len(y))\n",
    "\n",
    "plt.text(-3,35,s)\n",
    "\n",
    "\n",
    "# plt.savefig('rituals_vs_rotatedStrength_tscores_to_nullNEW.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print csv file with r values for each brain-behav correlation and each code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_perception_r_fisherz = result_perception_r_fisherz.rename(columns={0: \"perception_brain_behav_R_fisherZ\"})\n",
    "result_schema_r_fisherz = result_schema_r_fisherz.rename(columns={0: \"schema_brain_behav_R_fisherZ\"})\n",
    "result_rotated_r_fisherz = result_rotated_r_fisherz.rename(columns={0: \"rotated_brain_behav_R_fisherZ\"})\n",
    "result_path_r_fisherz = result_path_r_fisherz.rename(columns={0: \"path_brain_behav_R_fisherZ\"})\n",
    "result_rotatedandperception_r_fisherz = result_rotatedandperception_r_fisherz.rename(columns={0: \"result_rotatedandperception_r_fisherz\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined = pd.concat([result_perception_r_fisherz,\n",
    "                      result_schema_r_fisherz,\n",
    "                      result_rotated_r_fisherz,\n",
    "                      result_path_r_fisherz,\n",
    "                      result_rotatedandperception_r_fisherz], axis=1)\n",
    "\n",
    "\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv('brain_behav_Rvalues_fisherZ.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rotatedandperception_r_fisherz = result_rotatedandperception_r_fisherz.rename(columns={0: \"result_rotatedandperception_perception_r_fisherz\"})\n",
    "result_rotatedandperception_r_fisherz.to_csv('brain_behav_Rvalues_fisherZ_addition.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for rituals\n",
    "\n",
    "result_perception_r_rituals_fisherz = result_perception_r_rituals_fisherz.rename(columns={0: \"perception_brain_behav_R_fisherZ\"})\n",
    "result_schema_r_rituals_fisherz = result_schema_r_rituals_fisherz.rename(columns={0: \"schema_brain_behav_R_fisherZ\"})\n",
    "result_rotated_r_rituals_fisherz = result_rotated_r_rituals_fisherz.rename(columns={0: \"rotated_brain_behav_R_fisherZ\"})\n",
    "result_path_r_rituals_fisherz = result_path_r_rituals_fisherz.rename(columns={0: \"path_brain_behav_R_fisherZ\"})\n",
    "result_rotatedandperception_r_rituals_fisherz = result_rotatedandperception_r_rituals_fisherz.rename(columns={0: \"result_rotatedandperception_r_rituals_fisherz\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined2 = pd.concat([result_perception_r_rituals_fisherz,\n",
    "                      result_schema_r_rituals_fisherz,\n",
    "                      result_rotated_r_rituals_fisherz,\n",
    "                      result_path_r_rituals_fisherz,\n",
    "                      result_rotatedandperception_r_rituals_fisherz], axis=1)\n",
    "\n",
    "\n",
    "combined2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined2.to_csv('brain_behav_Rvalues_fisherZ_rituals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rotatedandperception_r_rituals_fisherz = result_rotatedandperception_r_rituals_fisherz.rename(columns={0: \"result_rotatedandperception_perception_r_fisherz\"})\n",
    "result_rotatedandperception_r_rituals_fisherz.to_csv('brain_behav_Rvalues_fisherZ_rituals_addition.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
