{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code to create whole-brain maps and fdr-correction for each of the 4 neural codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "from nilearn import image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.font_manager\n",
    "plt.rcParams.update({'font.size': 16})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_id_to_distilled_searchlights(K, distill_numLights,\n",
    "                      exaggerated_0, weight_it, cap_zero, fraction, threshold, by_sil):\n",
    "    cluster_id_to_distilled_lights = {}\n",
    "    for cluster_id in range(1,K+1):\n",
    "        ranks_dir = \"/scratch/gpfs/scollin/clustering_output/kmeans_searchlight_ranks/K\" + str(K) + \"/kmeans\" + str(K) + \"cluster\" + str(cluster_id) + \"_ranks\"\n",
    "        if by_sil:\n",
    "            ranks_dir += \"_by_silhouttes\"\n",
    "        else:\n",
    "            if exaggerated_0:\n",
    "                ranks_dir += (\"_Consider0_T\" + str(threshold))\n",
    "            else:\n",
    "                ranks_dir += \"_NoConsider0\"\n",
    "            if weight_it:\n",
    "                ranks_dir += (\"_WeightByMean\")\n",
    "            else:\n",
    "                ranks_dir += \"_NoWeightByMean\"\n",
    "            if cap_zero:\n",
    "                ranks_dir += \"_CapZero\"\n",
    "            else:\n",
    "                ranks_dir += \"_NoCapZero\"\n",
    "        ranks_dir += \".csv\"\n",
    "        print(ranks_dir)\n",
    "        ranks_df = pd.read_csv(ranks_dir)\n",
    "        ranked_searchlights_in_cluster = ranks_df[\"searchlights_in_cluster\"].tolist()\n",
    "        if fraction:\n",
    "            cluster_id_to_distilled_lights[cluster_id] = ranked_searchlights_in_cluster[0:int(distill_numLights*len(ranked_searchlights_in_cluster))]\n",
    "        else: \n",
    "            cluster_id_to_distilled_lights[cluster_id] = ranked_searchlights_in_cluster[0:distill_numLights]\n",
    "\n",
    "    return cluster_id_to_distilled_lights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sil_avg_list = []\n",
    "exaggerated_0 = False\n",
    "weight_it = True\n",
    "cap_zero = False\n",
    "distill_it = False\n",
    "distill_numLights = 0.2\n",
    "fraction = True\n",
    "threshold = 1.7\n",
    "by_sil = False\n",
    "matplotlib.rcParams['font.family'] = \"sans-serif\"\n",
    "matplotlib.rcParams['font.sans-serif'] =  \"Arial\"\n",
    "for K in range(2,7):\n",
    "    # get silhouttes\n",
    "    in_dir = \"/scratch/gpfs/scollin/clustering_output/kmeans_silhouette_tval/kmeans\" + str(K) + \"_silhouttes_tval.csv\"\n",
    "    labels_dir = \"/scratch/gpfs/scollin/clustering_output/kmeans_assignments_tval/kmeans_\" + str(K) + \"clusters_tval.csv\"\n",
    "    df = pd.read_csv(labels_dir)\n",
    "    cluster_labels = np.array(df[\"cluster_assignment\"].tolist())\n",
    "    searchlight_np = np.array((df[\"searchlight\"].tolist()))\n",
    "    sample_silhouette_values = np.loadtxt(in_dir, delimiter = \",\")\n",
    "    print(len(sample_silhouette_values))\n",
    "    silhouette_avg = sum(sample_silhouette_values) / len(sample_silhouette_values)\n",
    "    sil_avg_list.append(silhouette_avg)\n",
    "    if distill_it:\n",
    "        cluster_id_to_distilled_lights = get_cluster_id_to_distilled_searchlights(K, distill_numLights, exaggerated_0, weight_it, cap_zero, fraction, threshold, by_sil)\n",
    "        all_lights_thisK = []\n",
    "        for key in cluster_id_to_distilled_lights:\n",
    "            for x in cluster_id_to_distilled_lights[key]:\n",
    "                all_lights_thisK.append(x)\n",
    "        filter_list = [True if light_id in all_lights_thisK else False for light_id in searchlight_np]\n",
    "        searchlight_np = searchlight_np[filter_list]\n",
    "        cluster_labels = cluster_labels[filter_list]\n",
    "        sample_silhouette_values = sample_silhouette_values[filter_list]\n",
    "    print(len(sample_silhouette_values))\n",
    "    print(K, \"clusters\", \", Average silhoutte Score:\", silhouette_avg)\n",
    "    #plt.hist(sample_silhouette_values)\n",
    "    n_clusters = K\n",
    "    # plot them\n",
    "    fig, (ax1) = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(25, 15)\n",
    "    ax1.set_xlim([-0.1, 0.4])\n",
    "    ax1.set_ylim([0, len(cluster_labels) + (n_clusters + 1) * 10])\n",
    "    y_lower = 10\n",
    "    for i in range(1,n_clusters + 1):\n",
    "      \n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "        color = cm.nipy_spectral(1)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "        ax1.set_title(\"K = \" + str(i))\n",
    "        ax1.set_xlabel(\"the silhouette coefficient values\")\n",
    "        ax1.set_ylabel(\"cluster label\")\n",
    "        ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "        ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "        ax1.set_xticks([-0.1, 0, 0.2])\n",
    "        \n",
    "    #changed by SHPC FEB 23\n",
    "    save_name = \"sil_K\" + str(i) + \".png\"\n",
    "    plt.savefig(save_name, format = \"png\")\n",
    "        \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x for x in range(2,7)], sil_avg_list)\n",
    "plt.title(\"silhoutte avg across K clusters in range [2,7]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sort_list(ranks, lights):\n",
    "    zipped_pairs = zip(ranks, lights)\n",
    "    new_ranks = []\n",
    "    new_lights = []\n",
    "    for r,l in sorted(zipped_pairs, reverse= True):\n",
    "        new_ranks.append(r)\n",
    "        new_lights.append(l)\n",
    "    return new_ranks, new_lights\n",
    "\n",
    "\n",
    "# for each cluster, get the mean of that cluster\n",
    "K = 5\n",
    "labels_dir = \"/scratch/gpfs/rk1593/clustering_output/kmeans_assignments_tval/kmeans_\" + str(K) + \"clusters_tval.csv\"\n",
    "df = pd.read_csv(labels_dir)\n",
    "cluster_labels = df[\"cluster_assignment\"]\n",
    "searchlight_list = np.load(\"/scratch/gpfs/rk1593/clustering_output/kmeans_assignments_tval/master_searchlight_tval.npy\")\n",
    "X = np.load(\"/scratch/gpfs/rk1593/clustering_output/kmeans_assignments_tval/master_X_list_tval.npy\")\n",
    "silhouttes_dir = \"/scratch/gpfs/rk1593/clustering_output/kmeans_silhouette_tval/kmeans\" + str(K) + \"_silhouttes_tval.csv\"\n",
    "searchlights_rank_list = np.loadtxt(silhouttes_dir, delimiter = \",\")\n",
    "\n",
    "for cluster_id in set(cluster_labels):\n",
    "    searchlights_in_cluster = searchlight_list[cluster_labels == cluster_id]\n",
    "    searchlights_in_cluster_ranks = searchlights_rank_list[cluster_labels == cluster_id]\n",
    "    new_ranks, new_lights = sort_list(ranks = searchlights_in_cluster_ranks, lights = searchlights_in_cluster)\n",
    "    output_dir = \"/scratch/gpfs/rk1593/clustering_output/kmeans_searchlight_ranks/K\" + str(K) + \"/kmeans\" + str(K) + \"cluster\" + str(cluster_id) + \"_ranks_by_silhouttes.csv\"\n",
    "    df = pd.DataFrame({\"searchlights_rank\": new_ranks,\n",
    "                       \"searchlights_in_cluster\":new_lights})\n",
    "    df.to_csv(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cluster_id_to_distilled_searchlights(K, distill_numLights,\n",
    "                      exaggerated_0, weight_it, cap_zero, fraction, threshold, by_sil):\n",
    "    cluster_id_to_distilled_lights = {}\n",
    "    for cluster_id in range(1,K+1):\n",
    "        ranks_dir = \"/scratch/gpfs/scollin/clustering_output/kmeans_searchlight_ranks/K\" + str(K) + \"/kmeans\" + str(K) + \"cluster\" + str(cluster_id) + \"_ranks\"\n",
    "        if by_sil:\n",
    "            ranks_dir += \"_by_silhouttes\"\n",
    "        else:\n",
    "            if exaggerated_0:\n",
    "                ranks_dir += (\"_Consider0_T\" + str(threshold)) \n",
    "            else:\n",
    "                ranks_dir += \"_NoConsider0\"\n",
    "            if weight_it:\n",
    "                ranks_dir += (\"_WeightByMean\")\n",
    "            else:\n",
    "                ranks_dir += \"_NoWeightByMean\"\n",
    "            if cap_zero:\n",
    "                ranks_dir += \"_CapZero\"\n",
    "            else:\n",
    "                ranks_dir += \"_NoCapZero\"\n",
    "        ranks_dir += \".csv\"\n",
    "        print(ranks_dir)\n",
    "        ranks_df = pd.read_csv(ranks_dir)\n",
    "        ranked_searchlights_in_cluster = ranks_df[\"searchlights_in_cluster\"].tolist()\n",
    "        if fraction:\n",
    "            cluster_id_to_distilled_lights[cluster_id] = ranked_searchlights_in_cluster[0:int(distill_numLights*len(ranked_searchlights_in_cluster))]\n",
    "        else: \n",
    "            cluster_id_to_distilled_lights[cluster_id] = ranked_searchlights_in_cluster[0:distill_numLights]\n",
    "\n",
    "    return cluster_id_to_distilled_lights\n",
    "\n",
    "def plot_colored_brain(K,cluster_assignment_csv_path, brain_image_path, optional_focus = None,\n",
    "                               colored_brain_np = [], distill_it = False, distill_numLights = 1000,by_sil = True,\n",
    "                      exaggerated_0 = False, weight_it = True,\n",
    "                       cap_zero = False, fraction = False, threshold = None):\n",
    "    \"\"\"\n",
    "    This function plots a colored brain based on the cluster assignment of kmodes\n",
    "\n",
    "    cluster_assignment_csv_path: data frame with columns: \"cluster_assignment\", \"searchlight\", \"features\"\n",
    "\n",
    "    brain_image_path: shape (97, 115, 97) image which will be used to get the affine and header\n",
    "\n",
    "    output_path: where these plots will end up saved\n",
    "    \"\"\"\n",
    "    # get the brain_image_path\n",
    "    matplotlib.rcParams['font.family'] = \"sans-serif\"\n",
    "    matplotlib.rcParams['font.sans-serif'] =  \"Arial\"\n",
    "    img = nib.load(brain_image_path)\n",
    "    if distill_it:\n",
    "        cluster_id_to_distilled_lights = get_cluster_id_to_distilled_searchlights(K, distill_numLights, exaggerated_0, weight_it, cap_zero, fraction, threshold, by_sil)\n",
    "    # get colored_brain_np if it is not fed in\n",
    "    if len(colored_brain_np) == 0:\n",
    "        # get the cluster assignment\n",
    "        df = pd.read_csv(cluster_assignment_csv_path)\n",
    "        colored_brain_np = np.zeros(shape=(97, 115, 97))\n",
    "        # colored_brain_np = colored_brain_np.astype(float)\n",
    "        # populate the brain_np with the cluster assignment\n",
    "        for index,row in df.iterrows():\n",
    "            light_id_splitted = row[\"searchlight\"].split(\"_\")\n",
    "            light_id_str = row[\"searchlight\"]\n",
    "            cluster_id = int(row[\"cluster_assignment\"])\n",
    "            if distill_it and light_id_str not in cluster_id_to_distilled_lights[cluster_id]:\n",
    "                continue\n",
    "            x = int(light_id_splitted[0])\n",
    "            y = int(light_id_splitted[1])\n",
    "            z = int(light_id_splitted[2])\n",
    "            colored_brain_np[x,y,z] = int(row[\"cluster_assignment\"])\n",
    "    original_colored_brain_np = copy.copy(colored_brain_np)\n",
    "    if optional_focus != None:\n",
    "        colored_brain_np[colored_brain_np != optional_focus] = 0\n",
    "    # turn into nifti and plot with nilearn\n",
    "    colored_brain = nib.Nifti1Image(colored_brain_np, affine=img.affine, header = img.header, extra = img.extra)\n",
    "    print(\"optional_focus: \", optional_focus)\n",
    "    print(\"len(np.unique(colored_brain_np)): \", len(np.unique(colored_brain_np)))\n",
    "    print(np.unique(colored_brain_np))\n",
    "    display = plotting.plot_roi(colored_brain, draw_cross = False, cut_coords = (-4,-30,20), colorbar = True, cmap = cm.get_cmap('Spectral', 20), title =  \"\" )#\"K = \" + str(K) + \" & Focus Cluster = \" + str(optional_focus) )\n",
    "    plt.savefig(\"map5.pdf\", format = \"pdf\")\n",
    "    plt.show()#savefig(\"map.pdf\", format = \"pdf\")\n",
    "    display.close()\n",
    "    # added by SHPC\n",
    "    nib.save(colored_brain,\"colored_brain_k2.nii\")\n",
    "    return original_colored_brain_np\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save brain map with all p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "output_dir = \"/scratch/gpfs/scollin/clustering_output/brainmap_pvals/each_searchlight/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "allSearchlightsIMG = \"/home/scollin/wedding_schema/code/python/kmeans/notebooks/colored_brain_K5_allSearchlights.nii\" \n",
    "img3 = nib.load(allSearchlightsIMG)\n",
    "dataimg3 = img3.get_fdata()\n",
    "\n",
    "result_schema = []\n",
    "\n",
    "colored_brain_np_schema = np.zeros(shape=(97, 115, 97))\n",
    "colored_brain_np_path = np.zeros(shape=(97, 115, 97))\n",
    "colored_brain_np_perception = np.zeros(shape=(97, 115, 97))\n",
    "colored_brain_np_rotated = np.zeros(shape=(97, 115, 97))\n",
    "\n",
    "for filename in os.listdir('/scratch/gpfs/scollin/clustering_output/brainmap_pvals/each_searchlight/'):\n",
    "    filename = os.path.join(filename)\n",
    "    f = open(output_dir+filename, \"r\")\n",
    "    fileContent = f.read()\n",
    "    \n",
    "    # convert string of file to dictionary for easier access\n",
    "    res = json.loads(fileContent)\n",
    "    \n",
    "    resultValueSCHEMA = res['schema'] \n",
    "    resultValuePATH = res['path'] \n",
    "    resultValuePERCEPTION = res['perception'] \n",
    "    resultValueROTATED = res['rotated']\n",
    "    \n",
    "    # save x y z values of searchlight ID\n",
    "    filename = filename.split(\"_\")\n",
    "    \n",
    "    colored_brain_np_schema[int(filename[0]),int(filename[1]),int(filename[2])] = resultValueSCHEMA\n",
    "    colored_brain_np_path[int(filename[0]),int(filename[1]),int(filename[2])] = resultValuePATH\n",
    "    colored_brain_np_perception[int(filename[0]),int(filename[1]),int(filename[2])] = resultValuePERCEPTION\n",
    "    colored_brain_np_rotated[int(filename[0]),int(filename[1]),int(filename[2])] = resultValueROTATED\n",
    "\n",
    "brain_image_path = \"/home/scollin/wedding_schema/code/python/kmeans/rentireAAL_wfupickatlas.nii\" \n",
    "img = nib.load(brain_image_path)\n",
    "\n",
    "colored_brain_schema = nib.Nifti1Image(colored_brain_np_schema, affine=img.affine, header = img.header, extra = img.extra)\n",
    "nib.save(colored_brain_schema,\"schema_pVals_all.nii\")     \n",
    "\n",
    "colored_brain_path = nib.Nifti1Image(colored_brain_np_path, affine=img.affine, header = img.header, extra = img.extra)\n",
    "nib.save(colored_brain_path,\"path_pVals_all.nii\")   \n",
    "\n",
    "colored_brain_perception = nib.Nifti1Image(colored_brain_np_perception, affine=img.affine, header = img.header, extra = img.extra)\n",
    "nib.save(colored_brain_perception,\"perception_pVals_all.nii\")   \n",
    "\n",
    "colored_brain_rotated = nib.Nifti1Image(colored_brain_np_rotated, affine=img.affine, header = img.header, extra = img.extra)\n",
    "nib.save(colored_brain_rotated,\"rotated_pVals_all.nii\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save fdr corrected fdr brain map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allPvalsIMG = \"/home/scollin/wedding_schema/code/python/kmeans/notebooks/schema_pVals_all.nii\" \n",
    "\n",
    "brain_image_path = \"/home/scollin/wedding_schema/code/python/kmeans/rentireAAL_wfupickatlas.nii\" \n",
    "img = nib.load(brain_image_path)\n",
    "\n",
    "img3 = nib.load(allPvalsIMG)\n",
    "dataimg3 = img3.get_fdata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set outside brain voxels to nans\n",
    "dataimgmask= img.get_fdata()\n",
    "outsideBrain_coords = np.where(dataimgmask==0)\n",
    "dataimg3[outsideBrain_coords] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get voxels without NaNs\n",
    "nonnan_mask = ~np.isnan(dataimg3)\n",
    "nonnan_coords = np.where(nonnan_mask)\n",
    "\n",
    "# Mask p-value map to exclude NaNs\n",
    "nonnan_p = dataimg3[nonnan_mask]\n",
    "#nonnan_data = dataimg3[nonnan_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get FDR-controlled q-values\n",
    "nonnan_q = multipletests(nonnan_p, method='fdr_by')[1]\n",
    "threshold = .05\n",
    "print(f\"{np.sum(dataimg3 < threshold)} significant voxels \"\n",
    "      f\"at uncorrected p value of {threshold}\")\n",
    "print(f\"{np.sum(nonnan_q < threshold)} significant voxels \"\n",
    "      f\"controlling FDR at {threshold}\")\n",
    "\n",
    "# Threshold according FDR-controlled threshold\n",
    "#nonnan_data[nonnan_q >= threshold] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinsert thresholded back into whole brain image\n",
    "p_thresh = np.full(dataimg3.shape, np.nan)\n",
    "p_thresh[nonnan_coords] = nonnan_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_thresh_image = nib.Nifti1Image(p_thresh, affine=img3.affine, header = img3.header)\n",
    "nib.save(p_thresh_image,\"schema_pVals_thresh_fdr0.05.nii\") \n",
    "\n",
    "# Reinsert thresholded back into whole brain image but now INVERTED (1-correct p value)\n",
    "p_thresh = np.full(dataimg3.shape, np.nan)\n",
    "p_thresh[nonnan_coords] = 1-nonnan_q\n",
    "\n",
    "p_thresh_image = nib.Nifti1Image(p_thresh, affine=img3.affine, header = img3.header)\n",
    "nib.save(p_thresh_image,\"schema_pVals_thresh_fdr0.05_inverted.nii\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## same for perception\n",
    "\n",
    "allPvalsIMG = \"/home/scollin/wedding_schema/code/python/kmeans/notebooks/perception_pVals_all.nii\" \n",
    "\n",
    "img3 = nib.load(allPvalsIMG)\n",
    "dataimg3 = img3.get_fdata()\n",
    "\n",
    "# set outside brain voxels to nans\n",
    "dataimg3[outsideBrain_coords] = np.nan\n",
    "\n",
    "# Get voxels without NaNs\n",
    "nonnan_mask = ~np.isnan(dataimg3)\n",
    "nonnan_coords = np.where(nonnan_mask)\n",
    "\n",
    "# Mask p-value map to exclude NaNs\n",
    "nonnan_p = dataimg3[nonnan_mask]\n",
    "\n",
    "# Get FDR-controlled q-values\n",
    "nonnan_q = multipletests(nonnan_p, method='fdr_by')[1]\n",
    "threshold = .05\n",
    "print(f\"{np.sum(dataimg3 < threshold)} significant voxels \"\n",
    "      f\"at uncorrected p value of {threshold}\")\n",
    "print(f\"{np.sum(nonnan_q < threshold)} significant voxels \"\n",
    "      f\"controlling FDR at {threshold}\")\n",
    "\n",
    "# Reinsert thresholded back into whole brain image\n",
    "p_thresh = np.full(dataimg3.shape, np.nan)\n",
    "p_thresh[nonnan_coords] = nonnan_q\n",
    "\n",
    "p_thresh_image = nib.Nifti1Image(p_thresh, affine=img3.affine, header = img3.header)\n",
    "nib.save(p_thresh_image,\"perception_pVals_thresh_fdr0.05.nii\") \n",
    "\n",
    "# Reinsert thresholded back into whole brain image but now INVERTED (1-correct p value)\n",
    "p_thresh = np.full(dataimg3.shape, np.nan)\n",
    "p_thresh[nonnan_coords] = 1-nonnan_q\n",
    "\n",
    "p_thresh_image = nib.Nifti1Image(p_thresh, affine=img3.affine, header = img3.header)\n",
    "nib.save(p_thresh_image,\"perception_pVals_thresh_fdr0.05_inverted.nii\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## same for path\n",
    "\n",
    "allPvalsIMG = \"/home/scollin/wedding_schema/code/python/kmeans/notebooks/path_pVals_all.nii\" \n",
    "\n",
    "img3 = nib.load(allPvalsIMG)\n",
    "dataimg3 = img3.get_fdata()\n",
    "\n",
    "# set outside brain voxels to nans\n",
    "dataimg3[outsideBrain_coords] = np.nan\n",
    "\n",
    "# Get voxels without NaNs\n",
    "nonnan_mask = ~np.isnan(dataimg3)\n",
    "nonnan_coords = np.where(nonnan_mask)\n",
    "\n",
    "# Mask p-value map to exclude NaNs\n",
    "nonnan_p = dataimg3[nonnan_mask]\n",
    "\n",
    "# Get FDR-controlled q-values\n",
    "nonnan_q = multipletests(nonnan_p, method='fdr_by')[1]\n",
    "threshold = .05\n",
    "print(f\"{np.sum(dataimg3 < threshold)} significant voxels \"\n",
    "      f\"at uncorrected p value of {threshold}\")\n",
    "print(f\"{np.sum(nonnan_q < threshold)} significant voxels \"\n",
    "      f\"controlling FDR at {threshold}\")\n",
    "\n",
    "# Reinsert thresholded back into whole brain image\n",
    "p_thresh = np.full(dataimg3.shape, np.nan)\n",
    "p_thresh[nonnan_coords] = nonnan_q\n",
    "\n",
    "p_thresh_image = nib.Nifti1Image(p_thresh, affine=img3.affine, header = img3.header)\n",
    "nib.save(p_thresh_image,\"path_pVals_thresh_fdr0.05.nii\") \n",
    "\n",
    "# Reinsert thresholded back into whole brain image but now INVERTED (1-correct p value)\n",
    "p_thresh = np.full(dataimg3.shape, np.nan)\n",
    "p_thresh[nonnan_coords] = 1-nonnan_q\n",
    "\n",
    "p_thresh_image = nib.Nifti1Image(p_thresh, affine=img3.affine, header = img3.header)\n",
    "nib.save(p_thresh_image,\"path_pVals_thresh_fdr0.05_inverted.nii\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## same for rotated\n",
    "\n",
    "allPvalsIMG = \"/home/scollin/wedding_schema/code/python/kmeans/notebooks/rotated_pVals_all.nii\" \n",
    "\n",
    "img3 = nib.load(allPvalsIMG)\n",
    "dataimg3 = img3.get_fdata()\n",
    "\n",
    "# set outside brain voxels to nans\n",
    "dataimg3[outsideBrain_coords] = np.nan\n",
    "\n",
    "# Get voxels without NaNs\n",
    "nonnan_mask = ~np.isnan(dataimg3)\n",
    "nonnan_coords = np.where(nonnan_mask)\n",
    "\n",
    "# Mask p-value map to exclude NaNs\n",
    "nonnan_p = dataimg3[nonnan_mask]\n",
    "\n",
    "# Get FDR-controlled q-values\n",
    "nonnan_q = multipletests(nonnan_p, method='fdr_by')[1]\n",
    "threshold = .05\n",
    "print(f\"{np.sum(dataimg3 < threshold)} significant voxels \"\n",
    "      f\"at uncorrected p value of {threshold}\")\n",
    "print(f\"{np.sum(nonnan_q < threshold)} significant voxels \"\n",
    "      f\"controlling FDR at {threshold}\")\n",
    "\n",
    "# Reinsert thresholded back into whole brain image\n",
    "p_thresh = np.full(dataimg3.shape, np.nan)\n",
    "p_thresh[nonnan_coords] = nonnan_q\n",
    "\n",
    "p_thresh_image = nib.Nifti1Image(p_thresh, affine=img3.affine, header = img3.header)\n",
    "nib.save(p_thresh_image,\"rotated_pVals_thresh_fdr0.05.nii\") \n",
    "\n",
    "# Reinsert thresholded back into whole brain image but now INVERTED (1-correct p value)\n",
    "p_thresh = np.full(dataimg3.shape, np.nan)\n",
    "p_thresh[nonnan_coords] = 1-nonnan_q\n",
    "\n",
    "p_thresh_image = nib.Nifti1Image(p_thresh, affine=img3.affine, header = img3.header)\n",
    "nib.save(p_thresh_image,\"rotated_pVals_thresh_fdr0.05_inverted.nii\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
